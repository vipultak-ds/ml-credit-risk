{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c3f0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### TRAINING_script (FIXED - Hyperparameter Grid from YAML)\n",
    "\n",
    "import mlflow\n",
    "import time\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ‚úÖ Import evaluation logging functions\n",
    "from evaluation import create_eval_table_if_not_exists, log_run_to_table\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ CREDIT RISK TRAINING - MULTI MODEL MODE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# üî• LOAD CONFIG FILES\n",
    "\n",
    "with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "    pipeline_cfg = yaml.safe_load(f)\n",
    "\n",
    "with open(\"experiments_config.yml\", \"r\") as f:\n",
    "    experiments_cfg = yaml.safe_load(f)\n",
    "\n",
    "# üî• GET MODELS TO TRAIN (No Git Variables / Widgets)\n",
    "\n",
    "def get_models_to_train():\n",
    "    available_models = list(experiments_cfg.get(\"models\", {}).keys())\n",
    "\n",
    "    if not available_models:\n",
    "        raise ValueError(\"‚ùå No models defined in experiments_config.yml\")\n",
    "\n",
    "    print(f\"‚úÖ Training ALL models: {available_models}\")\n",
    "    return available_models\n",
    "\n",
    "try:\n",
    "    MODELS_TO_TRAIN = get_models_to_train()\n",
    "    print(f\"\\nüìã Models to train: {MODELS_TO_TRAIN}\\n\")\n",
    "except ValueError as e:\n",
    "    print(str(e))\n",
    "    dbutils.notebook.exit(\"FAILED: Invalid MODELS_TO_TRAIN configuration\")\n",
    "\n",
    "# üî• PIPELINE SETTINGS\n",
    "\n",
    "BASE_EXPERIMENT_NAME = pipeline_cfg[\"experiment\"][\"name\"]\n",
    "MODEL_ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "RAW_INPUT_TABLE = pipeline_cfg[\"data\"][\"input_table\"]\n",
    "FEATURES = pipeline_cfg[\"data\"][\"features\"]\n",
    "LABEL_COL = pipeline_cfg[\"data\"][\"label\"]\n",
    "RUN_NAME_PREFIX = pipeline_cfg[\"experiment\"][\"run_name_prefix\"]\n",
    "\n",
    "# üî• LOAD DATA\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CreditRiskTraining\").getOrCreate()\n",
    "df = spark.read.table(RAW_INPUT_TABLE).toPandas()\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[LABEL_COL]\n",
    "\n",
    "if y.dtype == \"object\":\n",
    "    y = y.map({\"yes\": 1, \"no\": 0}).astype(int)\n",
    "\n",
    "# üî• PREPROCESSING\n",
    "\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "        (\"numeric\", StandardScaler(), numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# üî• TRAIN-TEST SPLIT\n",
    "\n",
    "stratify_option = y if pipeline_cfg[\"data\"][\"split\"][\"stratify\"] else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=pipeline_cfg[\"data\"][\"split\"][\"test_size\"],\n",
    "    stratify=stratify_option,\n",
    "    random_state=pipeline_cfg[\"data\"][\"split\"][\"random_state\"]\n",
    ")\n",
    "\n",
    "# üî• MLflow SETUP\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    \"random_forest\": RandomForestClassifier\n",
    "}\n",
    "\n",
    "# ‚úÖ MODEL TYPE TO SHORT NAME MAPPING\n",
    "MODEL_SHORT_NAMES = {\n",
    "    \"random_forest\": \"RF\"\n",
    "}\n",
    "\n",
    "def get_model_short_name(model_type):\n",
    "    if model_type in MODEL_SHORT_NAMES:\n",
    "        return MODEL_SHORT_NAMES[model_type]\n",
    "    words = model_type.split(\"_\")\n",
    "    return \"\".join([w[0].upper() for w in words if w])\n",
    "\n",
    "# ‚úÖ CREATE PARAM GRID FROM YAML hyperparameters\n",
    "\n",
    "def generate_param_combinations(hyperparam_dict: dict):\n",
    "    \"\"\"\n",
    "    Converts:\n",
    "      {\"a\":[1,2], \"b\":[3,4]}\n",
    "    Into:\n",
    "      [{\"a\":1,\"b\":3}, {\"a\":1,\"b\":4}, {\"a\":2,\"b\":3}, {\"a\":2,\"b\":4}]\n",
    "    \"\"\"\n",
    "    keys = list(hyperparam_dict.keys())\n",
    "    values_list = [hyperparam_dict[k] for k in keys]\n",
    "\n",
    "    combos = []\n",
    "    for values in product(*values_list):\n",
    "        combos.append(dict(zip(keys, values)))\n",
    "\n",
    "    return combos\n",
    "\n",
    "# üî• TRAIN LOOP\n",
    "\n",
    "for MODEL_TYPE in MODELS_TO_TRAIN:\n",
    "\n",
    "    if MODEL_TYPE not in MODEL_CLASSES:\n",
    "        print(f\"‚ö†Ô∏è  Skipping {MODEL_TYPE} - model class not found\")\n",
    "        continue\n",
    "\n",
    "    if MODEL_TYPE not in experiments_cfg[\"models\"]:\n",
    "        print(f\"‚ö†Ô∏è  Skipping {MODEL_TYPE} - not in experiments_config.yml\")\n",
    "        continue\n",
    "\n",
    "    # ‚úÖ CREATE MODEL-SPECIFIC EXPERIMENT NAME\n",
    "    model_short = get_model_short_name(MODEL_TYPE)\n",
    "    MODEL_EXPERIMENT_NAME = f\"{BASE_EXPERIMENT_NAME}_{model_short}\"\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üî¨ Setting experiment: {MODEL_EXPERIMENT_NAME}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    mlflow.set_experiment(MODEL_EXPERIMENT_NAME)\n",
    "\n",
    "    ModelClass = MODEL_CLASSES[MODEL_TYPE]\n",
    "\n",
    "    # ‚úÖ READ hyperparameters from YAML\n",
    "    hyperparams = experiments_cfg[\"models\"][MODEL_TYPE].get(\"hyperparameters\", {})\n",
    "\n",
    "    if not hyperparams:\n",
    "        print(f\"‚ö†Ô∏è No hyperparameters found for {MODEL_TYPE}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    PARAM_COMBINATIONS = generate_param_combinations(hyperparams)\n",
    "\n",
    "    print(f\"üéØ Training {MODEL_TYPE.upper()} - {len(PARAM_COMBINATIONS)} hyperparameter combinations\\n\")\n",
    "\n",
    "    # ‚úÖ Create eval table once (before runs start)\n",
    "    create_eval_table_if_not_exists()\n",
    "\n",
    "    for idx, params in enumerate(PARAM_COMBINATIONS, start=1):\n",
    "\n",
    "        exp_name = f\"{RUN_NAME_PREFIX}_{MODEL_TYPE}_run_{idx}\"\n",
    "\n",
    "        with mlflow.start_run(run_name=exp_name) as run:\n",
    "\n",
    "            model = ModelClass(**params)\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                (\"preprocessing\", preprocessor),\n",
    "                (\"model\", model)\n",
    "            ])\n",
    "\n",
    "            start = time.time()\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            train_time = round(time.time() - start, 4)\n",
    "\n",
    "            train_pred = pipeline.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, train_pred)\n",
    "\n",
    "            start_inf = time.time()\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            inference_time = round(time.time() - start_inf, 4)\n",
    "\n",
    "            if hasattr(pipeline.named_steps[\"model\"], \"predict_proba\"):\n",
    "                y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            else:\n",
    "                y_proba = None\n",
    "\n",
    "            metrics = {\n",
    "                \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
    "                \"test_precision\": precision_score(y_test, y_pred),\n",
    "                \"test_recall\": recall_score(y_test, y_pred),\n",
    "                \"test_f1\": f1_score(y_test, y_pred),\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"train_time\": train_time,\n",
    "                \"inference_time\": inference_time\n",
    "            }\n",
    "\n",
    "            if y_proba is not None:\n",
    "                metrics[\"test_roc_auc\"] = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "            for k, v in metrics.items():\n",
    "                mlflow.log_metric(k, v)\n",
    "\n",
    "            # Log params\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param(\"model_type\", MODEL_TYPE)\n",
    "            mlflow.log_param(\"experiment_name\", MODEL_EXPERIMENT_NAME)\n",
    "\n",
    "            signature = infer_signature(X_train, pipeline.predict(X_train))\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                pipeline,\n",
    "                artifact_path=MODEL_ARTIFACT_PATH,\n",
    "                signature=signature,\n",
    "                input_example=X_train.head(5)\n",
    "            )\n",
    "\n",
    "            # ‚úÖ NEW STEP: Log to Delta Evaluation Table\n",
    "            log_run_to_table(\n",
    "                model_name=exp_name,\n",
    "                model_type=MODEL_TYPE,\n",
    "                run_id=run.info.run_id,\n",
    "                experiment_name=MODEL_EXPERIMENT_NAME,\n",
    "                hyperparams=params,\n",
    "                metrics=metrics\n",
    "            )\n",
    "\n",
    "            print(f\"   ‚úÖ {exp_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéâ ALL MODELS TRAINING COMPLETED!\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
