{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d4986",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ---------------- LOAD PIPELINE CONFIG ----------------\n",
    "with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "    pipeline_cfg = yaml.safe_load(f)\n",
    "\n",
    "EVAL_TABLE = pipeline_cfg[\"tables\"][\"evaluation_log\"]\n",
    "TRACKED_METRICS = pipeline_cfg[\"metrics\"][\"classification\"][\"tracked_metrics\"]\n",
    "\n",
    "# Optional: duplicate handling config\n",
    "DUPLICATE_CFG = pipeline_cfg.get(\"tables\", {}).get(\"duplicate_handling\", {})\n",
    "DUPLICATE_ENABLED = DUPLICATE_CFG.get(\"enabled\", True)\n",
    "\n",
    "print(f\"✅ Evaluation Table: {EVAL_TABLE}\")\n",
    "print(f\"✅ Tracked Metrics: {TRACKED_METRICS}\")\n",
    "print(f\"✅ Duplicate Handling Enabled: {DUPLICATE_ENABLED}\")\n",
    "\n",
    "\n",
    "# ---------------- CREATE TABLE IF NOT EXISTS ----------------\n",
    "def create_eval_table_if_not_exists():\n",
    "    spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {EVAL_TABLE} (\n",
    "        model_name STRING,\n",
    "        model_type STRING,\n",
    "        run_id STRING,\n",
    "        experiment_name STRING,\n",
    "        created_timestamp TIMESTAMP,\n",
    "        hyperparameters STRING,\n",
    "        metrics STRING\n",
    "    )\n",
    "    USING DELTA\n",
    "    \"\"\")\n",
    "    print(f\"✅ Evaluation table ready: {EVAL_TABLE}\")\n",
    "\n",
    "\n",
    "# ---------------- DUPLICATE CHECK ----------------\n",
    "def is_duplicate(model_type: str, experiment_name: str, hyper_json: str) -> bool:\n",
    "    \"\"\"\n",
    "    Duplicate means:\n",
    "    same model_type + experiment_name + hyperparameters already exists\n",
    "    \"\"\"\n",
    "    if not DUPLICATE_ENABLED:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        df = spark.read.table(EVAL_TABLE).filter(\n",
    "            (col(\"model_type\") == model_type) &\n",
    "            (col(\"experiment_name\") == experiment_name) &\n",
    "            (col(\"hyperparameters\") == hyper_json)\n",
    "        )\n",
    "        return df.limit(1).count() > 0\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Duplicate check skipped (table read error): {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# ---------------- LOG ONE RUN TO DELTA ----------------\n",
    "def log_run_to_table(\n",
    "    model_name: str,\n",
    "    model_type: str,\n",
    "    run_id: str,\n",
    "    experiment_name: str,\n",
    "    hyperparams: dict,\n",
    "    metrics: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Stores:\n",
    "    - hyperparameters as JSON string\n",
    "    - metrics as JSON string (only tracked metrics)\n",
    "    - avoids duplicates\n",
    "    \"\"\"\n",
    "\n",
    "    # keep only tracked metrics\n",
    "    filtered_metrics = {k: metrics.get(k, None) for k in TRACKED_METRICS}\n",
    "\n",
    "    # JSON normalize (stable ordering)\n",
    "    hyper_json = json.dumps(hyperparams, sort_keys=True)\n",
    "    metrics_json = json.dumps(filtered_metrics, sort_keys=True)\n",
    "\n",
    "    # check duplicates\n",
    "    if is_duplicate(model_type, experiment_name, hyper_json):\n",
    "        print(f\"⚠️ Duplicate row detected. Skipping insert for run_id={run_id}\")\n",
    "        return\n",
    "\n",
    "    row = [{\n",
    "        \"model_name\": model_name,\n",
    "        \"model_type\": model_type,\n",
    "        \"run_id\": run_id,\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"created_timestamp\": datetime.utcnow(),\n",
    "        \"hyperparameters\": hyper_json,\n",
    "        \"metrics\": metrics_json\n",
    "    }]\n",
    "\n",
    "    df = spark.createDataFrame(row)\n",
    "    df.write.format(\"delta\").mode(\"append\").saveAsTable(EVAL_TABLE)\n",
    "\n",
    "    print(f\"✅ Logged evaluation row for run_id={run_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
