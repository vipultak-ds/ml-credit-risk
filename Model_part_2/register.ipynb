{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a4f91",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üéØ MODEL REGISTRATION SCRIPT - MULTI MODEL (DYNAMIC + FIXED)\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import sys\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, Optional, List\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, TimestampType, BooleanType\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ MODEL REGISTRATION SYSTEM - MULTI MODEL + DYNAMIC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ---------------------- LOAD CONFIG FILES ----------------------\n",
    "try:\n",
    "    with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "\n",
    "    with open(\"experiments_config.yml\", \"r\") as f:\n",
    "        experiments_cfg = yaml.safe_load(f)\n",
    "\n",
    "    print(\"‚úÖ Configuration files loaded\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load config: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ---------------------- OPTIONAL WIDGETS ----------------------\n",
    "# If running in Databricks job/notebook, this allows selecting models\n",
    "try:\n",
    "    dbutils.widgets.text(\"MODELS_TO_REGISTER\", \"all\", \"Models to Register (all or comma-separated)\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# ---------------------- INIT SPARK + MLFLOW ----------------------\n",
    "spark = SparkSession.builder.appName(\"ModelRegistrationMultiModel\").getOrCreate()\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = MlflowClient()\n",
    "\n",
    "# ---------------------- GLOBAL CONFIG ----------------------\n",
    "BASE_EXPERIMENT_NAME = pipeline_cfg[\"experiment\"][\"name\"]\n",
    "ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "\n",
    "PRIMARY_METRIC = pipeline_cfg[\"metrics\"][\"classification\"][\"primary_metric\"]\n",
    "DIRECTION = pipeline_cfg[\"metrics\"][\"classification\"][\"direction\"]\n",
    "\n",
    "DUP_CFG = pipeline_cfg[\"registry\"][\"duplicate_detection\"]\n",
    "DUPLICATE_CHECK_ENABLED = DUP_CFG.get(\"enabled\", True)\n",
    "TOLERANCE = DUP_CFG.get(\"tolerance\", 0.001)\n",
    "METRICS_TO_COMPARE = DUP_CFG.get(\"metrics_to_compare\", [])\n",
    "\n",
    "MODEL_NAMING_FMT = pipeline_cfg[\"models\"][\"naming\"][\"format\"]\n",
    "UC_CATALOG = pipeline_cfg[\"models\"][\"catalog\"]\n",
    "UC_SCHEMA = pipeline_cfg[\"models\"][\"schema\"]\n",
    "BASE_NAME = pipeline_cfg[\"models\"][\"base_name\"]\n",
    "\n",
    "# IMPORTANT: Your pipeline_config.yml currently DOES NOT have registration_log\n",
    "# so we provide a safe default table if missing\n",
    "REGISTRATION_LOG_TABLE = pipeline_cfg.get(\"tables\", {}).get(\n",
    "    \"registration_log\",\n",
    "    f\"{UC_CATALOG}.{UC_SCHEMA}.model_registration_log\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Primary Metric: {PRIMARY_METRIC} ({DIRECTION})\")\n",
    "print(f\"‚úÖ Artifact Path: {ARTIFACT_PATH}\")\n",
    "print(f\"‚úÖ Duplicate Detection: {DUPLICATE_CHECK_ENABLED} (tolerance={TOLERANCE})\")\n",
    "print(f\"‚úÖ Registration Log Table: {REGISTRATION_LOG_TABLE}\\n\")\n",
    "\n",
    "\n",
    "# ---------------------- MODEL SHORT NAME (DYNAMIC) ----------------------\n",
    "def get_model_short_name(model_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Makes short name like:\n",
    "      random_forest -> RF\n",
    "      logistic_regression -> LR\n",
    "      xgboost -> XGB\n",
    "    \"\"\"\n",
    "    words = model_type.split(\"_\")\n",
    "    return \"\".join([w[0].upper() for w in words if w])\n",
    "\n",
    "\n",
    "def get_experiment_name_for_model(model_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Training script uses:\n",
    "      /Shared/CreditRisk_ML_Experiments_RF\n",
    "    so we follow the same.\n",
    "    \"\"\"\n",
    "    return f\"{BASE_EXPERIMENT_NAME}_{get_model_short_name(model_type)}\"\n",
    "\n",
    "\n",
    "def get_uc_model_name(model_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses naming format from pipeline_config.yml\n",
    "    \"\"\"\n",
    "    return MODEL_NAMING_FMT.format(\n",
    "        catalog=UC_CATALOG,\n",
    "        schema=UC_SCHEMA,\n",
    "        base_name=BASE_NAME,\n",
    "        model_type=model_type\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------------- MODELS TO REGISTER (DYNAMIC) ----------------------\n",
    "def get_models_to_register() -> List[str]:\n",
    "    \"\"\"\n",
    "    Priority:\n",
    "    1) Databricks widget MODELS_TO_REGISTER\n",
    "    2) ENV MODELS_TO_REGISTER\n",
    "    3) Default: all models from experiments_config.yml\n",
    "    \"\"\"\n",
    "    available_models = list(experiments_cfg.get(\"models\", {}).keys())\n",
    "\n",
    "    if not available_models:\n",
    "        raise ValueError(\"‚ùå No models defined in experiments_config.yml\")\n",
    "\n",
    "    value = None\n",
    "    try:\n",
    "        value = dbutils.widgets.get(\"MODELS_TO_REGISTER\")\n",
    "        print(f\"üìå MODELS_TO_REGISTER from Widget: '{value}'\")\n",
    "    except:\n",
    "        value = os.getenv(\"MODELS_TO_REGISTER\", \"all\")\n",
    "        print(f\"üìå MODELS_TO_REGISTER from ENV: '{value}'\")\n",
    "\n",
    "    value = (value or \"\").strip()\n",
    "\n",
    "    if value.lower() == \"all\" or value == \"\":\n",
    "        return available_models\n",
    "\n",
    "    models = [m.strip() for m in value.split(\",\") if m.strip()]\n",
    "    invalid = [m for m in models if m not in available_models]\n",
    "\n",
    "    if invalid:\n",
    "        raise ValueError(f\"‚ùå Invalid models: {invalid} | Available: {available_models}\")\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "# ---------------------- REGISTRATION LOG TABLE SCHEMA ----------------------\n",
    "def get_table_schema():\n",
    "    return StructType([\n",
    "        StructField(\"timestamp\", TimestampType(), True),\n",
    "        StructField(\"run_id\", StringType(), True),\n",
    "        StructField(\"run_name\", StringType(), True),\n",
    "        StructField(\"model_type\", StringType(), True),\n",
    "        StructField(\"model_name\", StringType(), True),\n",
    "        StructField(\"experiment_name\", StringType(), True),\n",
    "        StructField(\"primary_metric\", StringType(), True),\n",
    "        StructField(\"primary_metric_value\", DoubleType(), True),\n",
    "        StructField(\"metrics_json\", StringType(), True),\n",
    "        StructField(\"params_json\", StringType(), True),\n",
    "        StructField(\"registered\", BooleanType(), True),\n",
    "        StructField(\"registered_version\", StringType(), True),\n",
    "        StructField(\"reason\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "\n",
    "def ensure_table_exists(table_name: str):\n",
    "    try:\n",
    "        spark.sql(f\"DESCRIBE TABLE {table_name}\")\n",
    "        print(f\"   ‚úÖ Table exists: {table_name}\")\n",
    "    except:\n",
    "        print(f\"   üÜï Creating Delta table: {table_name}\")\n",
    "        empty_df = spark.createDataFrame([], schema=get_table_schema())\n",
    "        empty_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(table_name)\n",
    "        print(f\"   ‚úÖ Table created: {table_name}\")\n",
    "\n",
    "\n",
    "def is_already_logged(run_id: str) -> bool:\n",
    "    try:\n",
    "        df = spark.sql(f\"\"\"\n",
    "            SELECT run_id\n",
    "            FROM {REGISTRATION_LOG_TABLE}\n",
    "            WHERE run_id = '{run_id}'\n",
    "            LIMIT 1\n",
    "        \"\"\")\n",
    "        return df.count() > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "# ---------------------- FETCH RUNS FROM MLFLOW EXPERIMENT ----------------------\n",
    "def get_runs_for_model(model_type: str) -> List[Dict]:\n",
    "    exp_name = get_experiment_name_for_model(model_type)\n",
    "\n",
    "    print(f\"   üî¨ Searching Experiment: {exp_name}\")\n",
    "\n",
    "    exp = mlflow.get_experiment_by_name(exp_name)\n",
    "    if exp is None:\n",
    "        print(f\"   ‚ö†Ô∏è Experiment not found: {exp_name}\")\n",
    "        return []\n",
    "\n",
    "    runs = client.search_runs(\n",
    "        [exp.experiment_id],\n",
    "        order_by=[f\"metrics.{PRIMARY_METRIC} DESC\"],\n",
    "        max_results=500\n",
    "    )\n",
    "\n",
    "    # filter only runs of this model_type\n",
    "    filtered = [r for r in runs if model_type in (r.info.run_name or \"\")]\n",
    "\n",
    "    results = []\n",
    "    for r in filtered:\n",
    "        results.append({\n",
    "            \"run_id\": r.info.run_id,\n",
    "            \"run_name\": r.info.run_name or \"unnamed_run\",\n",
    "            \"params\": r.data.params,\n",
    "            \"metrics\": r.data.metrics,\n",
    "            \"primary_metric\": r.data.metrics.get(PRIMARY_METRIC),\n",
    "            \"model_uri\": f\"runs:/{r.info.run_id}/{ARTIFACT_PATH}\",\n",
    "            \"experiment_name\": exp_name\n",
    "        })\n",
    "\n",
    "    print(f\"   ‚úÖ Found {len(results)} runs for {model_type}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# ---------------------- DUPLICATE CHECK IN REGISTRY ----------------------\n",
    "def is_duplicate_model(new_model: Dict, model_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Duplicate means:\n",
    "    - all METRICS_TO_COMPARE are within tolerance\n",
    "    - AND params are exactly same\n",
    "    \"\"\"\n",
    "    if not DUPLICATE_CHECK_ENABLED:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "        if not versions:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Could not fetch model versions: {e}\")\n",
    "        return False\n",
    "\n",
    "    for v in versions:\n",
    "        try:\n",
    "            existing_run = client.get_run(v.run_id)\n",
    "\n",
    "            # compare metrics\n",
    "            all_metrics_match = True\n",
    "            for metric_name in METRICS_TO_COMPARE:\n",
    "                old_val = existing_run.data.metrics.get(metric_name, 0)\n",
    "                new_val = new_model[\"metrics\"].get(metric_name, 0)\n",
    "\n",
    "                if abs(old_val - new_val) > TOLERANCE:\n",
    "                    all_metrics_match = False\n",
    "                    break\n",
    "\n",
    "            # compare params\n",
    "            params_match = (existing_run.data.params == new_model[\"params\"])\n",
    "\n",
    "            if all_metrics_match and params_match:\n",
    "                return True\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# ---------------------- REGISTER MODEL ----------------------\n",
    "def register_model(new_model: Dict, model_name: str) -> Optional[str]:\n",
    "    try:\n",
    "        reg = mlflow.register_model(new_model[\"model_uri\"], model_name)\n",
    "        return str(reg.version)\n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ùå Registration failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def log_decision(model: Dict, model_type: str, model_name: str, registered: bool, version: Optional[str], reason: str):\n",
    "    record = {\n",
    "        \"timestamp\": datetime.now(),\n",
    "        \"run_id\": model[\"run_id\"],\n",
    "        \"run_name\": model[\"run_name\"],\n",
    "        \"model_type\": model_type,\n",
    "        \"model_name\": model_name,\n",
    "        \"experiment_name\": model[\"experiment_name\"],\n",
    "        \"primary_metric\": PRIMARY_METRIC,\n",
    "        \"primary_metric_value\": float(model[\"primary_metric\"]) if model[\"primary_metric\"] else 0.0,\n",
    "        \"metrics_json\": json.dumps({k: model[\"metrics\"].get(k) for k in METRICS_TO_COMPARE}, sort_keys=True),\n",
    "        \"params_json\": json.dumps(model[\"params\"], sort_keys=True),\n",
    "        \"registered\": registered,\n",
    "        \"registered_version\": version if version else \"N/A\",\n",
    "        \"reason\": reason\n",
    "    }\n",
    "\n",
    "    spark_df = spark.createDataFrame([record], schema=get_table_schema())\n",
    "\n",
    "    spark_df.write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .saveAsTable(REGISTRATION_LOG_TABLE)\n",
    "\n",
    "\n",
    "# ---------------------- PROCESS ONE MODEL TYPE ----------------------\n",
    "def process_model_type(model_type: str):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üöÄ PROCESSING MODEL TYPE: {model_type.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    model_name = get_uc_model_name(model_type)\n",
    "    print(f\"üì¶ UC Model Name: {model_name}\")\n",
    "\n",
    "    runs = get_runs_for_model(model_type)\n",
    "    if not runs:\n",
    "        print(f\"   ‚ö†Ô∏è No runs found for {model_type}\")\n",
    "        return {\"registered\": 0, \"skipped\": 0, \"total\": 0}\n",
    "\n",
    "    registered_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for idx, model in enumerate(runs, start=1):\n",
    "        print(f\"\\n   [{idx}/{len(runs)}] Run: {model['run_name']} | run_id={model['run_id']}\")\n",
    "\n",
    "        # skip if already logged\n",
    "        if is_already_logged(model[\"run_id\"]):\n",
    "            print(\"      ‚è≠Ô∏è Already logged ‚Üí skip\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        # duplicate check in registry\n",
    "        if is_duplicate_model(model, model_name):\n",
    "            print(\"      ‚ö†Ô∏è Duplicate detected in Registry ‚Üí skip\")\n",
    "            log_decision(model, model_type, model_name, False, None, \"Duplicate metrics+params ‚Üí skipped\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        # register\n",
    "        version = register_model(model, model_name)\n",
    "        if version:\n",
    "            print(f\"      ‚úÖ Registered: {model_name} v{version}\")\n",
    "            log_decision(model, model_type, model_name, True, version, \"Registered successfully\")\n",
    "            registered_count += 1\n",
    "        else:\n",
    "            log_decision(model, model_type, model_name, False, None, \"Registration failed\")\n",
    "            skipped_count += 1\n",
    "\n",
    "    return {\"registered\": registered_count, \"skipped\": skipped_count, \"total\": len(runs)}\n",
    "\n",
    "\n",
    "# ---------------------- MAIN ----------------------\n",
    "def main():\n",
    "    ensure_table_exists(REGISTRATION_LOG_TABLE)\n",
    "\n",
    "    try:\n",
    "        model_types = get_models_to_register()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"\\nüìã Models to register: {model_types}\")\n",
    "\n",
    "    overall = {\"registered\": 0, \"skipped\": 0, \"total\": 0}\n",
    "\n",
    "    for m in model_types:\n",
    "        stats = process_model_type(m)\n",
    "        overall[\"registered\"] += stats[\"registered\"]\n",
    "        overall[\"skipped\"] += stats[\"skipped\"]\n",
    "        overall[\"total\"] += stats[\"total\"]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üéâ ALL MODEL REGISTRATION COMPLETED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"‚úÖ Total Registered: {overall['registered']}\")\n",
    "    print(f\"‚ö†Ô∏è Total Skipped: {overall['skipped']}\")\n",
    "    print(f\"üìä Total Processed: {overall['total']}\")\n",
    "    print(f\"üìå Registration Log Table: {REGISTRATION_LOG_TABLE}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
