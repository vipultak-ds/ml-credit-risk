{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c571ec4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üöÄ CREDIT RISK TRAINING - MULTI MODEL SUPPORT\n",
    "\n",
    "%pip install scikit-learn pyyaml xgboost\n",
    "\n",
    "import mlflow\n",
    "import time\n",
    "import yaml\n",
    "import sys\n",
    "import os  # ‚úÖ NEW: required for Git / Env variables\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ CREDIT RISK TRAINING - MULTI MODEL MODE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ==========================================\n",
    "# üî• LOAD BOTH CONFIG FILES\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nüìã Loading configuration files...\")\n",
    "\n",
    "with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "    pipeline_cfg = yaml.safe_load(f)\n",
    "\n",
    "with open(\"experiments_config.yml\", \"r\") as f:\n",
    "    experiments_cfg = yaml.safe_load(f)\n",
    "\n",
    "print(\"‚úÖ Configs loaded successfully\")\n",
    "\n",
    "# ==========================================\n",
    "# üî• GET MODELS TO TRAIN (Databricks Job Safe)\n",
    "# ==========================================\n",
    "\n",
    "try:\n",
    "    MODELS_TO_TRAIN_ENV = dbutils.widgets.get(\"MODELS_TO_TRAIN\")\n",
    "except:\n",
    "    MODELS_TO_TRAIN_ENV = None\n",
    "\n",
    "if not MODELS_TO_TRAIN_ENV:\n",
    "    raise ValueError(\"‚ùå MODELS_TO_TRAIN job parameter is not set\")\n",
    "\n",
    "MODELS_TO_TRAIN = [m.strip() for m in MODELS_TO_TRAIN_ENV.split(\",\")]\n",
    "\n",
    "print(f\"\\n‚úÖ Models to train: {MODELS_TO_TRAIN}\")\n",
    "\n",
    "# ==========================================\n",
    "# 1Ô∏è‚É£ Extract Pipeline Settings (SAME AS BEFORE)\n",
    "# ==========================================\n",
    "\n",
    "EXPERIMENT_NAME = pipeline_cfg[\"experiment\"][\"name\"]\n",
    "MODEL_ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "RAW_INPUT_TABLE = pipeline_cfg[\"data\"][\"input_table\"]\n",
    "FEATURES = pipeline_cfg[\"data\"][\"features\"]\n",
    "LABEL_COL = pipeline_cfg[\"data\"][\"label\"]\n",
    "RUN_NAME_PREFIX = pipeline_cfg[\"experiment\"][\"run_name_prefix\"]\n",
    "\n",
    "# ==========================================\n",
    "# 2Ô∏è‚É£ Load Raw Data (SAME AS BEFORE)\n",
    "# ==========================================\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CreditRiskTraining\").getOrCreate()\n",
    "df = spark.read.table(RAW_INPUT_TABLE).toPandas()\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[LABEL_COL]\n",
    "\n",
    "if y.dtype == \"object\":\n",
    "    y = y.map({\"yes\": 1, \"no\": 0}).astype(int)\n",
    "\n",
    "# ==========================================\n",
    "# 3Ô∏è‚É£ Preprocessing (SAME AS BEFORE)\n",
    "# ==========================================\n",
    "\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "        (\"numeric\", StandardScaler(), numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4Ô∏è‚É£ Train-Test Split (SAME AS BEFORE)\n",
    "# ==========================================\n",
    "\n",
    "stratify_option = y if pipeline_cfg[\"data\"][\"split\"][\"stratify\"] else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=pipeline_cfg[\"data\"][\"split\"][\"test_size\"],\n",
    "    stratify=stratify_option,\n",
    "    random_state=pipeline_cfg[\"data\"][\"split\"][\"random_state\"]\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 5Ô∏è‚É£ MLflow Setup (SAME AS BEFORE)\n",
    "# ==========================================\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# ==========================================\n",
    "# üî• MODEL CLASS MAPPING\n",
    "# ==========================================\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    \"random_forest\": RandomForestClassifier,\n",
    "    \"xgboost\": XGBClassifier,\n",
    "    \"logistic_regression\": LogisticRegression\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 6Ô∏è‚É£ TRAIN EACH MODEL TYPE (MAIN LOOP)\n",
    "# ==========================================\n",
    "\n",
    "for MODEL_TYPE in MODELS_TO_TRAIN:\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üöÄ Training Model: {MODEL_TYPE.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    if MODEL_TYPE not in MODEL_CLASSES:\n",
    "        print(f\"‚ùå Unsupported model type: {MODEL_TYPE}\")\n",
    "        continue\n",
    "\n",
    "    if MODEL_TYPE not in experiments_cfg[\"models\"]:\n",
    "        print(f\"‚ùå No experiments found for {MODEL_TYPE} in experiments_config.yml\")\n",
    "        continue\n",
    "\n",
    "    ModelClass = MODEL_CLASSES[MODEL_TYPE]\n",
    "    model_config = experiments_cfg[\"models\"][MODEL_TYPE]\n",
    "    EXPERIMENT_LIST = model_config[\"experiments\"]\n",
    "\n",
    "    print(f\"üîç Running {len(EXPERIMENT_LIST)} experiments for {MODEL_TYPE}\")\n",
    "\n",
    "    for exp in EXPERIMENT_LIST:\n",
    "        exp_name = f\"{RUN_NAME_PREFIX}_{MODEL_TYPE}_{exp['name']}\"\n",
    "        params = exp[\"params\"].copy()\n",
    "\n",
    "        with mlflow.start_run(run_name=exp_name):\n",
    "\n",
    "            model = ModelClass(**params)\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                (\"preprocessing\", preprocessor),\n",
    "                (\"model\", model)\n",
    "            ])\n",
    "\n",
    "            start = time.time()\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            train_time = round(time.time() - start, 4)\n",
    "\n",
    "            train_pred = pipeline.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, train_pred)\n",
    "\n",
    "            start_inf = time.time()\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            inference_time = round(time.time() - start_inf, 4)\n",
    "\n",
    "            y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            metrics = {\n",
    "                \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
    "                \"test_precision\": precision_score(y_test, y_pred),\n",
    "                \"test_recall\": recall_score(y_test, y_pred),\n",
    "                \"test_f1\": f1_score(y_test, y_pred),\n",
    "                \"test_roc_auc\": roc_auc_score(y_test, y_proba),\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"train_time\": train_time,\n",
    "                \"inference_time\": inference_time\n",
    "            }\n",
    "\n",
    "            for k, v in metrics.items():\n",
    "                mlflow.log_metric(k, v)\n",
    "\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param(\"model_type\", MODEL_TYPE)\n",
    "\n",
    "            signature = infer_signature(X_train, pipeline.predict(X_train))\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                pipeline,\n",
    "                artifact_path=MODEL_ARTIFACT_PATH,\n",
    "                signature=signature,\n",
    "                input_example=X_train.head(5)\n",
    "            )\n",
    "\n",
    "            print(f\"   ‚úÖ {exp_name} completed\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üéâ {MODEL_TYPE.upper()} TRAINING COMPLETED!\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# ==========================================\n",
    "# üéâ FINAL SUMMARY\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéâ ALL MODELS TRAINING COMPLETED!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"‚úÖ Trained models: {', '.join(MODELS_TO_TRAIN)}\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
