{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c571ec4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### TRAINING_script\n",
    "\n",
    "%pip install scikit-learn pyyaml xgboost\n",
    "\n",
    "import mlflow\n",
    "import time\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ CREDIT RISK TRAINING - MULTI MODEL MODE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# üî• LOAD CONFIG FILES\n",
    "\n",
    "with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "    pipeline_cfg = yaml.safe_load(f)\n",
    "\n",
    "with open(\"experiments_config.yml\", \"r\") as f:\n",
    "    experiments_cfg = yaml.safe_load(f)\n",
    "\n",
    "# üîπ ENSURE WIDGET EXISTS (REQUIRED FOR DATABRICKS JOBS)\n",
    "try:\n",
    "    dbutils.widgets.text(\n",
    "        \"MODELS_TO_TRAIN\",\n",
    "        os.getenv(\"MODELS_TO_TRAIN\", \"\"),\n",
    "        \"Models to Train\"\n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# üî• GET MODELS TO TRAIN (Git / Job Variable)\n",
    "\n",
    "def get_models_to_train():\n",
    "    try:\n",
    "        val = dbutils.widgets.get(\"MODELS_TO_TRAIN\")\n",
    "    except:\n",
    "        val = os.getenv(\"MODELS_TO_TRAIN\")\n",
    "\n",
    "    if not val or val.lower() == \"none\":\n",
    "        raise ValueError(\"‚ùå MODELS_TO_TRAIN is not set or invalid\")\n",
    "\n",
    "    return [m.strip() for m in val.split(\",\") if m.strip()]\n",
    "\n",
    "MODELS_TO_TRAIN = get_models_to_train()\n",
    "\n",
    "# üî• EXPERIMENT NAME HELPER\n",
    "\n",
    "def get_experiment_name_for_model(model_type, base_experiment_name):\n",
    "    model_abbrev_map = {\n",
    "        \"random_forest\": \"RF\",\n",
    "        \"xgboost\": \"XGB\",\n",
    "        \"logistic_regression\": \"LR\"\n",
    "    }\n",
    "\n",
    "    if \"/\" in base_experiment_name:\n",
    "        path, base = base_experiment_name.rsplit(\"/\", 1)\n",
    "        base = base.replace(\"_ML_Experiments\", \"\").replace(\"_Experiments\", \"\")\n",
    "        parent = f\"{path}/{base}_Experiments\"\n",
    "    else:\n",
    "        base = base_experiment_name.replace(\"_ML_Experiments\", \"\").replace(\"_Experiments\", \"\")\n",
    "        parent = f\"{base}_Experiments\"\n",
    "\n",
    "    abbrev = model_abbrev_map.get(model_type, model_type[:3].upper())\n",
    "    return f\"{parent}/{abbrev}_Experiments\"\n",
    "\n",
    "# üî• PIPELINE SETTINGS\n",
    "\n",
    "BASE_EXPERIMENT_NAME = pipeline_cfg[\"experiment\"][\"name\"]\n",
    "MODEL_ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "RAW_INPUT_TABLE = pipeline_cfg[\"data\"][\"input_table\"]\n",
    "FEATURES = pipeline_cfg[\"data\"][\"features\"]\n",
    "LABEL_COL = pipeline_cfg[\"data\"][\"label\"]\n",
    "RUN_NAME_PREFIX = pipeline_cfg[\"experiment\"][\"run_name_prefix\"]\n",
    "\n",
    "# üî• LOAD DATA\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CreditRiskTraining\").getOrCreate()\n",
    "df = spark.read.table(RAW_INPUT_TABLE).toPandas()\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[LABEL_COL]\n",
    "\n",
    "if y.dtype == \"object\":\n",
    "    y = y.map({\"yes\": 1, \"no\": 0}).astype(int)\n",
    "\n",
    "# üî• PREPROCESSING\n",
    "\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "        (\"numeric\", StandardScaler(), numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# üî• TRAIN-TEST SPLIT\n",
    "\n",
    "stratify_option = y if pipeline_cfg[\"data\"][\"split\"][\"stratify\"] else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=pipeline_cfg[\"data\"][\"split\"][\"test_size\"],\n",
    "    stratify=stratify_option,\n",
    "    random_state=pipeline_cfg[\"data\"][\"split\"][\"random_state\"]\n",
    ")\n",
    "\n",
    "# üî• MLflow SETUP\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    \"random_forest\": RandomForestClassifier,\n",
    "    \"xgboost\": XGBClassifier,\n",
    "    \"logistic_regression\": LogisticRegression\n",
    "}\n",
    "\n",
    "# üî• TRAIN LOOP\n",
    "\n",
    "for MODEL_TYPE in MODELS_TO_TRAIN:\n",
    "\n",
    "    if MODEL_TYPE not in MODEL_CLASSES:\n",
    "        continue\n",
    "\n",
    "    if MODEL_TYPE not in experiments_cfg[\"models\"]:\n",
    "        continue\n",
    "\n",
    "    EXPERIMENT_NAME = get_experiment_name_for_model(MODEL_TYPE, BASE_EXPERIMENT_NAME)\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "    ModelClass = MODEL_CLASSES[MODEL_TYPE]\n",
    "    EXPERIMENT_LIST = experiments_cfg[\"models\"][MODEL_TYPE][\"experiments\"]\n",
    "\n",
    "    for exp in EXPERIMENT_LIST:\n",
    "\n",
    "        exp_name = f\"{RUN_NAME_PREFIX}_{MODEL_TYPE}_{exp['name']}\"\n",
    "        params = exp[\"params\"].copy()\n",
    "\n",
    "        with mlflow.start_run(run_name=exp_name):\n",
    "\n",
    "            model = ModelClass(**params)\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                (\"preprocessing\", preprocessor),\n",
    "                (\"model\", model)\n",
    "            ])\n",
    "\n",
    "            start = time.time()\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            train_time = round(time.time() - start, 4)\n",
    "\n",
    "            train_pred = pipeline.predict(X_train)\n",
    "            train_accuracy = accuracy_score(y_train, train_pred)\n",
    "\n",
    "            start_inf = time.time()\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            inference_time = round(time.time() - start_inf, 4)\n",
    "\n",
    "            if hasattr(pipeline.named_steps[\"model\"], \"predict_proba\"):\n",
    "                y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            else:\n",
    "                y_proba = None\n",
    "\n",
    "            metrics = {\n",
    "                \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
    "                \"test_precision\": precision_score(y_test, y_pred),\n",
    "                \"test_recall\": recall_score(y_test, y_pred),\n",
    "                \"test_f1\": f1_score(y_test, y_pred),\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"train_time\": train_time,\n",
    "                \"inference_time\": inference_time\n",
    "            }\n",
    "\n",
    "            if y_proba is not None:\n",
    "                metrics[\"test_roc_auc\"] = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "            for k, v in metrics.items():\n",
    "                mlflow.log_metric(k, v)\n",
    "\n",
    "            model_step = pipeline.named_steps[\"model\"]\n",
    "            if MODEL_TYPE == \"logistic_regression\" and hasattr(model_step, \"n_iter_\"):\n",
    "                mlflow.log_metric(\"lr_n_iterations\", int(np.max(model_step.n_iter_)))\n",
    "\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param(\"model_type\", MODEL_TYPE)\n",
    "            mlflow.log_param(\"experiment_name\", EXPERIMENT_NAME)\n",
    "\n",
    "            signature = infer_signature(X_train, pipeline.predict(X_train))\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                pipeline,\n",
    "                artifact_path=MODEL_ARTIFACT_PATH,\n",
    "                signature=signature,\n",
    "                input_example=X_train.head(5)\n",
    "            )\n",
    "\n",
    "print(\"üéâ ALL MODELS TRAINING COMPLETED!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
