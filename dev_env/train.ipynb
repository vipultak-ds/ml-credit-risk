{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c571ec4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üöÄ CREDIT RISK CLASSIFICATION TRAINING - FIXED VERSION\n",
    "\n",
    "%pip install scikit-learn pyyaml\n",
    "\n",
    "import mlflow\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ CREDIT RISK CLASSIFICATION TRAINING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    " \n",
    "# ‚úÖ LOAD PIPELINE CONFIGURATION\n",
    "\n",
    "print(\"\\nüìã Step 1: Loading pipeline configuration...\")\n",
    "\n",
    "try:\n",
    "    with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "\n",
    "    MODEL_TYPE = pipeline_cfg[\"model\"][\"type\"]\n",
    "    CATALOG = pipeline_cfg[\"model\"][\"catalog\"]\n",
    "    SCHEMA = pipeline_cfg[\"model\"][\"schema\"]\n",
    "    BASE_NAME = pipeline_cfg[\"model\"][\"base_name\"]\n",
    "    \n",
    "    EXPERIMENT_NAME = pipeline_cfg[\"experiment\"][\"name\"]\n",
    "    MODEL_ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "    RUN_NAME_PREFIX = pipeline_cfg[\"experiment\"][\"run_name_prefix\"]\n",
    "\n",
    "    PREPROCESSED_TABLE = pipeline_cfg[\"data\"][\"preprocessed_table\"]\n",
    "    LABEL_COL = \"label\"\n",
    "    \n",
    "    TEST_SIZE = pipeline_cfg[\"data\"][\"split\"][\"test_size\"]\n",
    "    RANDOM_STATE = pipeline_cfg[\"data\"][\"split\"][\"random_state\"]\n",
    "    STRATIFY = pipeline_cfg[\"data\"][\"split\"][\"stratify\"]\n",
    "\n",
    "    METRICS_CONFIG = pipeline_cfg[\"metrics\"][\"classification\"]\n",
    "    PRIMARY_METRIC = METRICS_CONFIG[\"primary_metric\"]\n",
    "    DIRECTION = METRICS_CONFIG[\"direction\"]\n",
    "    TRACKED_METRICS = METRICS_CONFIG[\"tracked_metrics\"]\n",
    "    THRESHOLD_METRICS = METRICS_CONFIG[\"threshold_metrics\"]\n",
    "\n",
    "    print(f\"‚úÖ Pipeline configuration loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR loading pipeline configuration: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 80)\n",
    " \n",
    "# ----- Load experiment configurations -----\n",
    "\n",
    "def load_experiment_configs(path=\"config.yml\"):\n",
    "    print(f\"\\nüìÑ Step 2: Loading experiment configurations...\")\n",
    "    \n",
    "    with open(path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    return config\n",
    " \n",
    "# ----- Convert PySpark Vector to array -----\n",
    "\n",
    "def vector_to_array(v):\n",
    "    return v.toArray() if hasattr(v, 'toArray') else np.array(v)\n",
    " \n",
    "# ----- Load preprocessed Delta table -----\n",
    "\n",
    "def load_preprocessed_data(spark):\n",
    "    print(f\"\\nüì¶ Loading PREPROCESSED data...\")\n",
    "    df = spark.read.format(\"delta\").table(PREPROCESSED_TABLE)\n",
    "    df_pd = df.toPandas()\n",
    "\n",
    "    X = np.array([vector_to_array(row) for row in df_pd['features']])\n",
    "    y = df_pd['label'].values\n",
    "\n",
    "    return X, y\n",
    " \n",
    "# ----- Train a single experiment -----\n",
    "\n",
    "def train_single_experiment(X, y, params, run_name):\n",
    "\n",
    "    stratify_param = y if STRATIFY else None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=TEST_SIZE, \n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=stratify_param\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "\n",
    "        # Log metadata\n",
    "        for param_name, param_value in params.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "\n",
    "        if \"random_state\" in params:\n",
    "            params.pop(\"random_state\")\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        metrics_dict = {\n",
    "            \"test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "            \"test_precision\": precision_score(y_test, y_test_pred, zero_division=0),\n",
    "            \"test_recall\": recall_score(y_test, y_test_pred, zero_division=0),\n",
    "            \"test_f1\": f1_score(y_test, y_test_pred, zero_division=0),\n",
    "            \"test_roc_auc\": roc_auc_score(y_test, y_test_proba)\n",
    "        }\n",
    "\n",
    "        for metric_name, metric_value in metrics_dict.items():\n",
    "            mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            artifact_path=MODEL_ARTIFACT_PATH,\n",
    "            signature=signature,\n",
    "            registered_model_name=None\n",
    "        )\n",
    "\n",
    "        # --- ‚≠ê NEW FEATURE IMPORTANCE DELTA LOGIC ADDED HERE ‚≠ê ---\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature_index': range(len(model.feature_importances_)),\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "\n",
    "            importance_file = \"feature_importance.csv\"\n",
    "            feature_importance.to_csv(importance_file, index=False)\n",
    "            mlflow.log_artifact(importance_file)\n",
    "\n",
    "            try:\n",
    "                FEATURE_IMPORTANCE_TABLE = pipeline_cfg[\"tables\"][\"feature_importance\"]\n",
    "\n",
    "                feature_importance[\"run_id\"] = run_id\n",
    "                feature_importance[\"timestamp\"] = datetime.now()\n",
    "\n",
    "                spark.createDataFrame(feature_importance) \\\n",
    "                    .write.format(\"delta\") \\\n",
    "                    .mode(\"append\") \\\n",
    "                    .saveAsTable(FEATURE_IMPORTANCE_TABLE)\n",
    "\n",
    "                print(f\"üìå Feature importance saved ‚Üí {FEATURE_IMPORTANCE_TABLE}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† Feature importance Delta logging failed: {e}\")\n",
    "\n",
    "        return run_id, metrics_dict\n",
    " \n",
    "# ----- MAIN EXECUTION -----\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"CreditRiskTraining\").getOrCreate()\n",
    "\n",
    "    X, y = load_preprocessed_data(spark)\n",
    "    config = load_experiment_configs()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for exp in config[\"experiments\"]:\n",
    "        run_id, metrics = train_single_experiment(\n",
    "            X, y, exp[\"params\"], f\"{RUN_NAME_PREFIX}_{exp['name']}\"\n",
    "        )\n",
    "        results.append({ \"name\": exp[\"name\"], \"run_id\": run_id, \"metrics\": metrics })\n",
    "\n",
    "    print(\"\\nüéâ Training completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
