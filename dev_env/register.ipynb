{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6faded",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üéØ MODEL REGISTRATION SCRIPT - MULTI MODEL\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, Optional, List\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType, BooleanType\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ MODEL REGISTRATION SYSTEM - MULTI MODEL + AUTOMATED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ---------------------- LOAD CONFIG FILES ----------------------\n",
    "try:\n",
    "    # Load pipeline config\n",
    "    with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    # Load experiments config (for reference if needed)\n",
    "    with open(\"experiments_config.yml\", \"r\") as f:\n",
    "        experiments_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"‚úÖ Configuration files loaded\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load config: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# ---------------------- CONFIGURATION CLASS ----------------------\n",
    "class Config:\n",
    "    def __init__(self, model_type: str):\n",
    "        \"\"\"\n",
    "        Initialize config for a specific model type\n",
    "        Args:\n",
    "            model_type: e.g., 'random_forest', 'xgboost'\n",
    "        \"\"\"\n",
    "        # ‚úÖ CHANGED: Use models section instead of model section\n",
    "        UC_CATALOG = pipeline_cfg[\"models\"][\"catalog\"]\n",
    "        UC_SCHEMA = pipeline_cfg[\"models\"][\"schema\"]\n",
    "        BASE_NAME = pipeline_cfg[\"models\"][\"base_name\"]\n",
    "        NAMING_FMT = pipeline_cfg[\"models\"][\"naming\"][\"format\"]\n",
    "\n",
    "        # Generate model name dynamically\n",
    "        self.MODEL_NAME = NAMING_FMT.format(\n",
    "            catalog=UC_CATALOG,\n",
    "            schema=UC_SCHEMA,\n",
    "            base_name=BASE_NAME,\n",
    "            model_type=model_type\n",
    "        )\n",
    "        \n",
    "        self.MODEL_TYPE = model_type\n",
    "        self.EXPERIMENT_NAME = pipeline_cfg[\"experiment\"][\"name\"]\n",
    "        self.ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "        self.PRIMARY_METRIC = pipeline_cfg[\"metrics\"][\"classification\"][\"primary_metric\"]\n",
    "\n",
    "        self.TOLERANCE = pipeline_cfg[\"registry\"][\"duplicate_detection\"][\"tolerance\"]\n",
    "        self.METRICS_TO_COMPARE = pipeline_cfg[\"registry\"][\"duplicate_detection\"][\"metrics_to_compare\"]\n",
    "        self.DUPLICATE_CHECK_ENABLED = pipeline_cfg[\"registry\"][\"duplicate_detection\"][\"enabled\"]\n",
    "\n",
    "        self.REGISTRATION_LOG_TABLE = pipeline_cfg[\"tables\"][\"registration_log\"]\n",
    "\n",
    "        # Slack webhook (optional)\n",
    "        self.SLACK_WEBHOOK = None\n",
    "        try:\n",
    "            self.SLACK_WEBHOOK = dbutils.secrets.get(\"shared-scope\", \"SLACK_WEBHOOK_URL\")\n",
    "            print(f\"   üîê Slack webhook loaded for {model_type}\")\n",
    "        except:\n",
    "            pass  # Silent fail - Slack is optional\n",
    "\n",
    "\n",
    "# ---------------------- SLACK NOTIFIER ----------------------\n",
    "class SlackNotifier:\n",
    "    def __init__(self, webhook_url: Optional[str]):\n",
    "        self.webhook_url = webhook_url\n",
    "\n",
    "    def send(self, message: str, level: str = \"info\"):\n",
    "        if not self.webhook_url:\n",
    "            return\n",
    "        emoji = {\"info\": \"‚ÑπÔ∏è\", \"success\": \"‚úÖ\", \"warning\": \"‚ö†Ô∏è\", \"error\": \"‚ùå\"}.get(level, \"‚ÑπÔ∏è\")\n",
    "        payload = {\"text\": f\"{emoji} {message}\"}\n",
    "\n",
    "        try:\n",
    "            requests.post(self.webhook_url, json=payload, timeout=5)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# ---------------------- INIT SPARK + MLFLOW ----------------------\n",
    "spark = SparkSession.builder.appName(\"ModelRegistrationMultiModel\").getOrCreate()\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = MlflowClient()\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(pipeline_cfg[\"experiment\"][\"name\"])\n",
    "if experiment is None:\n",
    "    raise Exception(f\"Experiment '{pipeline_cfg['experiment']['name']}' not found!\")\n",
    "\n",
    "\n",
    "# ---------------------- TABLE SCHEMA ----------------------\n",
    "def get_table_schema():\n",
    "    \"\"\"Define fixed schema for registration log table\"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"timestamp\", TimestampType(), True),\n",
    "        StructField(\"run_id\", StringType(), True),\n",
    "        StructField(\"run_name\", StringType(), True),\n",
    "        StructField(\"model_type\", StringType(), True),  # ‚úÖ NEW: Track model type\n",
    "        StructField(\"model_name\", StringType(), True),\n",
    "        StructField(\"primary_metric\", StringType(), True),\n",
    "        StructField(\"primary_metric_value\", DoubleType(), True),\n",
    "        StructField(\"metrics_json\", StringType(), True),\n",
    "        StructField(\"params_json\", StringType(), True),\n",
    "        StructField(\"registered\", BooleanType(), True),\n",
    "        StructField(\"registered_version\", StringType(), True),\n",
    "        StructField(\"reason\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "\n",
    "# ---------------------- TABLE CREATION ----------------------\n",
    "def ensure_table_exists(table_name: str):\n",
    "    try:\n",
    "        spark.sql(f\"DESCRIBE TABLE {table_name}\")\n",
    "        print(f\"   ‚úÖ Table exists: {table_name}\")\n",
    "    except:\n",
    "        print(f\"   üÜï Creating Delta table: {table_name}\")\n",
    "        schema = get_table_schema()\n",
    "        empty_df = spark.createDataFrame([], schema)\n",
    "        empty_df.write.format(\"delta\").option(\"overwriteSchema\", \"true\").saveAsTable(table_name)\n",
    "        print(f\"   ‚úÖ Table created: {table_name}\")\n",
    "\n",
    "\n",
    "# ---------------------- FETCH RUNS FOR MODEL TYPE ----------------------\n",
    "def get_runs_for_model(config: Config) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch runs for a specific model type from MLflow experiment\n",
    "    \"\"\"\n",
    "    print(f\"   üìç Fetching runs for {config.MODEL_TYPE}...\")\n",
    "    \n",
    "    runs = client.search_runs(\n",
    "        [experiment.experiment_id],\n",
    "        order_by=[f\"metrics.{config.PRIMARY_METRIC} DESC\"],\n",
    "        max_results=500\n",
    "    )\n",
    "\n",
    "    # ‚úÖ CHANGED: Filter runs by model type (check if model_type is in run_name)\n",
    "    filtered_runs = [\n",
    "        run for run in runs\n",
    "        if config.MODEL_TYPE in (run.info.run_name or \"\")\n",
    "    ]\n",
    "    \n",
    "    print(f\"   üîç Found {len(filtered_runs)} runs for {config.MODEL_TYPE}\")\n",
    "\n",
    "    return [{\n",
    "        \"run_id\": run.info.run_id,\n",
    "        \"run_name\": run.info.run_name or \"unnamed_run\",\n",
    "        \"metrics\": {m: run.data.metrics.get(m) for m in config.METRICS_TO_COMPARE if m in run.data.metrics},\n",
    "        \"params\": run.data.params,\n",
    "        \"primary_metric\": run.data.metrics.get(config.PRIMARY_METRIC),\n",
    "        \"model_uri\": f\"runs:/{run.info.run_id}/{config.ARTIFACT_PATH}\"\n",
    "    } for run in filtered_runs]\n",
    "\n",
    "\n",
    "# ---------------------- DUPLICATE CHECK ----------------------\n",
    "def is_duplicate_model(new_model: Dict, config: Config) -> bool:\n",
    "    \"\"\"Check if model with similar metrics and params already exists\"\"\"\n",
    "    if not config.DUPLICATE_CHECK_ENABLED:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        versions = client.search_model_versions(f\"name='{config.MODEL_NAME}'\")\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    for version in versions:\n",
    "        try:\n",
    "            run = client.get_run(version.run_id)\n",
    "\n",
    "            metrics_match = all(\n",
    "                abs((run.data.metrics.get(m) or 0) - (new_model[\"metrics\"].get(m) or 0)) <= config.TOLERANCE\n",
    "                for m in config.METRICS_TO_COMPARE\n",
    "            )\n",
    "\n",
    "            if metrics_match and run.data.params == new_model[\"params\"]:\n",
    "                print(f\"      ‚ö†Ô∏è  Duplicate detected ‚Üí Matches v{version.version}\")\n",
    "                return True\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# ---------------------- CHECK IF ALREADY LOGGED ----------------------\n",
    "def is_already_logged(run_id: str, table_name: str) -> bool:\n",
    "    \"\"\"Check if this run_id is already in the registration log\"\"\"\n",
    "    try:\n",
    "        existing = spark.sql(f\"\"\"\n",
    "            SELECT run_id \n",
    "            FROM {table_name} \n",
    "            WHERE run_id = '{run_id}'\n",
    "            LIMIT 1\n",
    "        \"\"\").count()\n",
    "\n",
    "        return existing > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "# ---------------------- REGISTER MODEL ----------------------\n",
    "def register_model(model: Dict, config: Config):\n",
    "    \"\"\"Register model to Unity Catalog Model Registry\"\"\"\n",
    "    if is_duplicate_model(model, config):\n",
    "        return None\n",
    "\n",
    "    print(f\"      üîÑ Registering to: {config.MODEL_NAME}\")\n",
    "    reg = mlflow.register_model(model[\"model_uri\"], config.MODEL_NAME)\n",
    "    version = reg.version\n",
    "\n",
    "    # Set version tags\n",
    "    try:\n",
    "        client.set_model_version_tag(config.MODEL_NAME, version, \"run_id\", model[\"run_id\"])\n",
    "        client.set_model_version_tag(config.MODEL_NAME, version, \"run_name\", model[\"run_name\"])\n",
    "        client.set_model_version_tag(config.MODEL_NAME, version, \"model_type\", config.MODEL_TYPE)\n",
    "        client.set_model_version_tag(config.MODEL_NAME, version, \"primary_metric\", config.PRIMARY_METRIC)\n",
    "        client.set_model_version_tag(config.MODEL_NAME, version, \"primary_metric_value\", str(round(model[\"primary_metric\"], 4)))\n",
    "        client.set_model_version_tag(config.MODEL_NAME, version, \"registered_timestamp\", datetime.now().isoformat())\n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è  Failed to set tags: {e}\")\n",
    "\n",
    "    print(f\"      ‚úÖ Registered as version: {version}\")\n",
    "    return version\n",
    "\n",
    "\n",
    "# ---------------------- LOG DECISION ----------------------\n",
    "def log_decision(model: Dict, config: Config, registered: bool, version: Optional[int], reason: str):\n",
    "    \"\"\"Log registration decision to Delta table\"\"\"\n",
    "\n",
    "    if is_already_logged(model[\"run_id\"], config.REGISTRATION_LOG_TABLE):\n",
    "        print(f\"      ‚ÑπÔ∏è  Already logged in table, skipping duplicate entry\")\n",
    "        return\n",
    "\n",
    "    version_str = str(version) if version is not None else \"N/A\"\n",
    "\n",
    "    record = {\n",
    "        \"timestamp\": datetime.now(),\n",
    "        \"run_id\": model[\"run_id\"],\n",
    "        \"run_name\": model[\"run_name\"],\n",
    "        \"model_type\": config.MODEL_TYPE,  # ‚úÖ NEW: Add model type\n",
    "        \"model_name\": config.MODEL_NAME,\n",
    "        \"primary_metric\": config.PRIMARY_METRIC,\n",
    "        \"primary_metric_value\": float(model[\"primary_metric\"]) if model[\"primary_metric\"] else 0.0,\n",
    "        \"metrics_json\": json.dumps(model[\"metrics\"]),\n",
    "        \"params_json\": json.dumps(model[\"params\"]),\n",
    "        \"registered\": registered,\n",
    "        \"registered_version\": version_str,\n",
    "        \"reason\": reason\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame([record])\n",
    "    spark_df = spark.createDataFrame(df, schema=get_table_schema())\n",
    "\n",
    "    try:\n",
    "        spark_df.write.format(\"delta\").mode(\"append\").saveAsTable(config.REGISTRATION_LOG_TABLE)\n",
    "        print(f\"      üìÑ Logged to: {config.REGISTRATION_LOG_TABLE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è  Failed to log: {e}\")\n",
    "\n",
    "\n",
    "# ---------------------- PROCESS SINGLE MODEL TYPE ----------------------\n",
    "def process_model_type(model_type: str, slack: SlackNotifier) -> Dict:\n",
    "    \"\"\"\n",
    "    Process registration for a single model type\n",
    "    Returns: dict with counts\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üöÄ PROCESSING MODEL TYPE: {model_type.upper()}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Create config for this model type\n",
    "    config = Config(model_type)\n",
    "    \n",
    "    print(f\"üì¶ Model Registry: {config.MODEL_NAME}\")\n",
    "    print(f\"üîç Primary Metric: {config.PRIMARY_METRIC}\")\n",
    "    print(f\"üõ°Ô∏è  Duplicate Check: {'ENABLED' if config.DUPLICATE_CHECK_ENABLED else 'DISABLED'}\\n\")\n",
    "    \n",
    "    # Ensure table exists\n",
    "    ensure_table_exists(config.REGISTRATION_LOG_TABLE)\n",
    "    \n",
    "    # Get runs for this model type\n",
    "    runs = get_runs_for_model(config)\n",
    "    \n",
    "    if not runs:\n",
    "        print(f\"   ‚ö†Ô∏è  No runs found for {model_type}\")\n",
    "        return {\"registered\": 0, \"skipped\": 0, \"total\": 0}\n",
    "    \n",
    "    registered_count = 0\n",
    "    skipped_count = 0\n",
    "    processed_run_ids = set()\n",
    "    \n",
    "    # Process each run\n",
    "    for idx, model in enumerate(runs, start=1):\n",
    "        \n",
    "        if model['run_id'] in processed_run_ids:\n",
    "            continue\n",
    "        \n",
    "        processed_run_ids.add(model['run_id'])\n",
    "        \n",
    "        print(f\"\\n   [{idx}/{len(runs)}] Processing: {model['run_name']}\")\n",
    "        print(f\"      Primary Metric ({config.PRIMARY_METRIC}): {model['primary_metric']:.4f}\")\n",
    "        \n",
    "        # Check if already logged\n",
    "        if is_already_logged(model['run_id'], config.REGISTRATION_LOG_TABLE):\n",
    "            print(f\"      ‚è≠Ô∏è  Skipped ‚Äî Already processed earlier\")\n",
    "            continue\n",
    "        \n",
    "        # Try to register\n",
    "        version = register_model(model, config)\n",
    "        \n",
    "        if version:\n",
    "            log_decision(model, config, True, version, \"‚úî Registered successfully\")\n",
    "            slack.send(f\"‚úÖ Registered: {config.MODEL_NAME} v{version} ({model['run_name']})\", \"success\")\n",
    "            registered_count += 1\n",
    "        else:\n",
    "            log_decision(model, config, False, None, \"‚ö† Duplicate - Skipped\")\n",
    "            slack.send(f\"‚ö†Ô∏è Duplicate skipped: {model['run_name']}\", \"warning\")\n",
    "            skipped_count += 1\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"‚úÖ {model_type.upper()} REGISTRATION COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"   ‚úÖ Registered: {registered_count}\")\n",
    "    print(f\"   ‚ö†Ô∏è  Skipped: {skipped_count}\")\n",
    "    print(f\"   üìä Total: {len(runs)}\")\n",
    "    \n",
    "    return {\n",
    "        \"registered\": registered_count,\n",
    "        \"skipped\": skipped_count,\n",
    "        \"total\": len(runs)\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------- MAIN ----------------------\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main registration pipeline:\n",
    "    1. Parse model types from Git variable\n",
    "    2. For each model type, process all runs\n",
    "    3. Register unique models to Unity Catalog\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ Starting Multi-Model Registration Pipeline...\\n\")\n",
    "    \n",
    "    # ‚úÖ CHANGED: Parse model types from Git variable\n",
    "    MODEL_TYPES_RAW = pipeline_cfg[\"models\"][\"enabled\"]\n",
    "    MODEL_TYPES = [m.strip() for m in MODEL_TYPES_RAW.split(\",\")]\n",
    "    \n",
    "    print(f\"üìã Models to register: {MODEL_TYPES}\\n\")\n",
    "    \n",
    "    # Initialize Slack notifier\n",
    "    slack = SlackNotifier(None)  # Will be initialized per model type\n",
    "    \n",
    "    # Track overall stats\n",
    "    total_stats = {\n",
    "        \"registered\": 0,\n",
    "        \"skipped\": 0,\n",
    "        \"total\": 0\n",
    "    }\n",
    "    \n",
    "    results_by_model = {}\n",
    "    \n",
    "    # Process each model type\n",
    "    for model_type in MODEL_TYPES:\n",
    "        try:\n",
    "            stats = process_model_type(model_type, slack)\n",
    "            results_by_model[model_type] = stats\n",
    "            \n",
    "            # Update totals\n",
    "            total_stats[\"registered\"] += stats[\"registered\"]\n",
    "            total_stats[\"skipped\"] += stats[\"skipped\"]\n",
    "            total_stats[\"total\"] += stats[\"total\"]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error processing {model_type}: {e}\")\n",
    "            results_by_model[model_type] = {\"error\": str(e)}\n",
    "            continue\n",
    "    \n",
    "    # ---------------------- FINAL SUMMARY ----------------------\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéâ ALL MODELS REGISTRATION COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nüìä Summary by Model Type:\")\n",
    "    print(\"-\" * 80)\n",
    "    for model_type, stats in results_by_model.items():\n",
    "        if \"error\" in stats:\n",
    "            print(f\"   ‚ùå {model_type}: {stats['error']}\")\n",
    "        else:\n",
    "            print(f\"   {model_type}:\")\n",
    "            print(f\"      ‚úÖ Registered: {stats['registered']}\")\n",
    "            print(f\"      ‚ö†Ô∏è  Skipped: {stats['skipped']}\")\n",
    "            print(f\"      üìä Total: {stats['total']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà Overall Statistics:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"   ‚úÖ Total Registered: {total_stats['registered']}\")\n",
    "    print(f\"   ‚ö†Ô∏è  Total Skipped: {total_stats['skipped']}\")\n",
    "    print(f\"   üìä Total Processed: {total_stats['total']}\")\n",
    "    print(f\"   üì¶ Registration Log: {pipeline_cfg['tables']['registration_log']}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
