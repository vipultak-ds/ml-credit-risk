{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6faded",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ðŸŽ¯ MODEL REGISTRATION SCRIPT - FIXED & CONFIG DRIVEN\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, Optional, List\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸŽ¯ MODEL REGISTRATION SYSTEM - AUTOMATED & DUPLICATE SAFE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ---------------------- LOAD PIPELINE CONFIG ----------------------\n",
    "try:\n",
    "    with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "    print(\"âœ… pipeline_config.yml loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to load config: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        MODEL_TYPE = pipeline_cfg[\"model\"][\"type\"]\n",
    "        UC_CATALOG = pipeline_cfg[\"model\"][\"catalog\"]\n",
    "        UC_SCHEMA = pipeline_cfg[\"model\"][\"schema\"]\n",
    "        BASE_NAME = pipeline_cfg[\"model\"][\"base_name\"]\n",
    "\n",
    "        self.MODEL_NAME = f\"{UC_CATALOG}.{UC_SCHEMA}.{BASE_NAME}_{MODEL_TYPE}\"\n",
    "        self.EXPERIMENT_NAME = pipeline_cfg[\"experiment\"][\"name\"]\n",
    "        self.ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "        self.PRIMARY_METRIC = pipeline_cfg[\"metrics\"][\"classification\"][\"primary_metric\"]\n",
    "\n",
    "        self.TOLERANCE = pipeline_cfg[\"registry\"][\"duplicate_detection\"][\"tolerance\"]\n",
    "        self.METRICS_TO_COMPARE = pipeline_cfg[\"registry\"][\"duplicate_detection\"][\"metrics_to_compare\"]\n",
    "        self.DUPLICATE_CHECK_ENABLED = pipeline_cfg[\"registry\"][\"duplicate_detection\"][\"enabled\"]\n",
    "\n",
    "        self.REGISTRATION_LOG_TABLE = pipeline_cfg[\"tables\"][\"registration_log\"]\n",
    "\n",
    "        self.SLACK_WEBHOOK = None\n",
    "        try:\n",
    "            self.SLACK_WEBHOOK = dbutils.secrets.get(\"shared-scope\", \"SLACK_WEBHOOK_URL\")\n",
    "            print(\"ðŸ” Slack webhook loaded\")\n",
    "        except:\n",
    "            print(\"âš  Slack webhook NOT configured (Optional)\")\n",
    "\n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(f\"\\nðŸ“Œ Model Registry: {config.MODEL_NAME}\")\n",
    "print(f\"ðŸ“Œ Duplicate Logic: {'ENABLED' if config.DUPLICATE_CHECK_ENABLED else 'DISABLED'}\")\n",
    "print(f\"ðŸ“Œ Primary Metric: {config.PRIMARY_METRIC}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# ---------------------- SLACK NOTIFIER ----------------------\n",
    "class SlackNotifier:\n",
    "    def __init__(self, webhook_url: Optional[str]):\n",
    "        self.webhook_url = webhook_url\n",
    "\n",
    "    def send(self, message: str, level: str = \"info\"):\n",
    "        if not self.webhook_url:\n",
    "            return\n",
    "        emoji = {\"info\": \"â„¹ï¸\", \"success\": \"âœ…\", \"warning\": \"âš ï¸\", \"error\": \"âŒ\"}.get(level, \"â„¹ï¸\")\n",
    "        payload = {\"text\": f\"{emoji} {message}\"}\n",
    "\n",
    "        try:\n",
    "            requests.post(self.webhook_url, json=payload, timeout=5)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "slack = SlackNotifier(config.SLACK_WEBHOOK)\n",
    "\n",
    "\n",
    "# ---------------------- INIT SPARK + MLFLOW ----------------------\n",
    "spark = SparkSession.builder.appName(\"ModelRegistration\").getOrCreate()\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = MlflowClient()\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(config.EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    raise Exception(f\"Experiment '{config.EXPERIMENT_NAME}' not found!\")\n",
    "\n",
    "\n",
    "# ---------------------- TABLE CREATION ----------------------\n",
    "def ensure_table_exists(table_name: str, df_schema, spark):\n",
    "    try:\n",
    "        spark.sql(f\"DESCRIBE TABLE {table_name}\")\n",
    "        print(f\"ðŸ“Œ Table exists: {table_name}\")\n",
    "    except:\n",
    "        print(f\"ðŸ†• Creating Delta table: {table_name}\")\n",
    "        empty_df = spark.createDataFrame([], df_schema)\n",
    "        empty_df.write.format(\"delta\").option(\"overwriteSchema\", \"true\").saveAsTable(table_name)\n",
    "        print(f\"âœ… Table created: {table_name}\")\n",
    "\n",
    "\n",
    "# ---------------------- FETCH RUNS ----------------------\n",
    "def get_all_runs() -> List[Dict]:\n",
    "    print(\"\\nðŸ“ Fetching experiment runs...\")\n",
    "    runs = client.search_runs([experiment.experiment_id], order_by=[f\"metrics.{config.PRIMARY_METRIC} DESC\"], max_results=500)\n",
    "\n",
    "    return [{\n",
    "        \"run_id\": run.info.run_id,\n",
    "        \"run_name\": run.info.run_name or \"unnamed_run\",\n",
    "        \"metrics\": {m: run.data.metrics.get(m) for m in config.METRICS_TO_COMPARE if m in run.data.metrics},\n",
    "        \"params\": run.data.params,\n",
    "        \"primary_metric\": run.data.metrics.get(config.PRIMARY_METRIC),\n",
    "        \"model_uri\": f\"runs:/{run.info.run_id}/{config.ARTIFACT_PATH}\"\n",
    "    } for run in runs]\n",
    "\n",
    "\n",
    "# ---------------------- DUPLICATE CHECK ----------------------\n",
    "def is_duplicate_model(new_model: Dict) -> bool:\n",
    "    if not config.DUPLICATE_CHECK_ENABLED:\n",
    "        return False\n",
    "\n",
    "    versions = client.search_model_versions(f\"name='{config.MODEL_NAME}'\")\n",
    "\n",
    "    for version in versions:\n",
    "        run = client.get_run(version.run_id)\n",
    "\n",
    "        metrics_match = all(\n",
    "            abs((run.data.metrics.get(m) or 0) - (new_model[\"metrics\"].get(m) or 0)) <= config.TOLERANCE\n",
    "            for m in config.METRICS_TO_COMPARE\n",
    "        )\n",
    "\n",
    "        if metrics_match and run.data.params == new_model[\"params\"]:\n",
    "            print(f\"âš  Duplicate model = Matches v{version.version}\")\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# ---------------------- REGISTER MODEL ----------------------\n",
    "def register_model(model: Dict):\n",
    "    if is_duplicate_model(model):\n",
    "        return None\n",
    "\n",
    "    reg = mlflow.register_model(model[\"model_uri\"], config.MODEL_NAME)\n",
    "    version = reg.version\n",
    "\n",
    "    try:\n",
    "        client.set_model_version_tag(config.MODEL_NAME, version, \"run_id\", model[\"run_id\"])\n",
    "        client.set_model_version_tag(config.MODEL_NAME, version, \"primary_metric\", str(model[\"primary_metric\"]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(f\"âœ… Registered as version: {version}\")\n",
    "    slack.send(f\"âœ… Registered {config.MODEL_NAME} v{version}\", \"success\")\n",
    "    return version\n",
    "\n",
    "\n",
    "# ---------------------- LOGGING DECISION ----------------------\n",
    "def log_decision(model, registered, version, reason):\n",
    "    df = pd.DataFrame([{\n",
    "        \"timestamp\": datetime.now(),\n",
    "        \"run_id\": model[\"run_id\"],\n",
    "        \"run_name\": model[\"run_name\"],\n",
    "        \"model_name\": config.MODEL_NAME,\n",
    "        \"primary_metric\": config.PRIMARY_METRIC,\n",
    "        \"primary_metric_value\": model[\"primary_metric\"],\n",
    "        \"metrics_json\": json.dumps(model[\"metrics\"]),\n",
    "        \"params_json\": json.dumps(model[\"params\"]),\n",
    "        \"registered\": registered,\n",
    "        \"registered_version\": str(version) if version else None,\n",
    "        \"reason\": reason\n",
    "    }])\n",
    "\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "\n",
    "    spark_df = spark_df.withColumn(\"registered_version\", spark_df.registered_version.cast(\"string\"))\n",
    "\n",
    "    ensure_table_exists(config.REGISTRATION_LOG_TABLE, spark_df.schema, spark)\n",
    "\n",
    "    delta = DeltaTable.forName(spark, config.REGISTRATION_LOG_TABLE)\n",
    "\n",
    "    delta.alias(\"t\").merge(\n",
    "        spark_df.alias(\"s\"),\n",
    "        \"t.run_name = s.run_name AND t.model_name = s.model_name\"\n",
    "    ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "\n",
    "    print(\"ðŸ“„ Logged.\")\n",
    "\n",
    "\n",
    "# ---------------------- MAIN ----------------------\n",
    "def main():\n",
    "    print(\"\\nðŸš€ Starting Model Registration...\\n\")\n",
    "\n",
    "    runs = get_all_runs()\n",
    "    if not runs:\n",
    "        print(\"âŒ No runs found!\")\n",
    "        return\n",
    "\n",
    "    registered = skipped = 0\n",
    "\n",
    "    processed_runs = set()  # ðŸ”¥ FEEDBACK FIX\n",
    "\n",
    "    for idx, model in enumerate(runs, start=1):\n",
    "\n",
    "        # Skip duplicate Slack/log execution for same run_id\n",
    "        if model['run_id'] in processed_runs:\n",
    "            continue\n",
    "\n",
    "        processed_runs.add(model['run_id'])\n",
    "\n",
    "        print(f\"\\n{'='*80}\\n[{idx}/{len(runs)}] â†’ {model['run_name']} (Metric: {model['primary_metric']})\")\n",
    "\n",
    "        version = register_model(model)\n",
    "\n",
    "        if version:\n",
    "            log_decision(model, True, version, \"âœ” Registered\")\n",
    "            registered += 1\n",
    "        else:\n",
    "            slack.send(f\"âš  Duplicate Skipped: {model['run_name']}\", \"warning\")\n",
    "            log_decision(model, False, None, \"âš  Duplicate Skipped\")\n",
    "            skipped += 1\n",
    "\n",
    "    print(\"\\nðŸŽ‰ Completed!\\n\")\n",
    "    print(f\"âœ” Registered: {registered}\")\n",
    "    print(f\"âš  Skipped: {skipped}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
