{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ PRODUCTION PROMOTION - NEW WORKFLOW (CONFIG-DRIVEN)\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import time\n",
    "import yaml\n",
    "import sys\n",
    "import traceback\n",
    "import requests\n",
    "from typing import Optional, Dict, Tuple\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ PRODUCTION PROMOTION (NEW WORKFLOW)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ‚úÖ LOAD PIPELINE CONFIGURATION\n",
    "\n",
    "print(\"\\nüìã Step 1: Loading configuration from pipeline_config.yml...\")\n",
    "\n",
    "try:\n",
    "    with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Configuration loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERROR: pipeline_config.yml not found!\")\n",
    "    print(\"üí° Please ensure pipeline_config.yml is in the notebook directory\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR loading configuration: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    " \n",
    "# ‚úÖ CONFIGURATION CLASS\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration manager - reads from pipeline_config.yml\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Model configuration\n",
    "        MODEL_TYPE = pipeline_cfg[\"model\"][\"type\"]\n",
    "        UC_CATALOG = pipeline_cfg[\"model\"][\"catalog\"]\n",
    "        UC_SCHEMA = pipeline_cfg[\"model\"][\"schema\"]\n",
    "        BASE_NAME = pipeline_cfg[\"model\"][\"base_name\"]\n",
    "        \n",
    "        self.MODEL_NAME = f\"{UC_CATALOG}.{UC_SCHEMA}.{BASE_NAME}_{MODEL_TYPE}\"\n",
    "        self.MODEL_TYPE = MODEL_TYPE\n",
    "        \n",
    "        # Aliases\n",
    "        self.STAGING_ALIAS = pipeline_cfg[\"aliases\"][\"staging\"]\n",
    "        self.PRODUCTION_ALIAS = pipeline_cfg[\"aliases\"][\"production\"]\n",
    "        self.BEST_ALIAS = pipeline_cfg[\"aliases\"][\"best\"]\n",
    "        \n",
    "        # Metrics configuration - support both classification and regression\n",
    "        if MODEL_TYPE in [\"random_forest\", \"logistic_regression\", \"xgboost_classifier\"]:\n",
    "            metrics_cfg = pipeline_cfg[\"metrics\"][\"classification\"]\n",
    "        else:\n",
    "            metrics_cfg = pipeline_cfg[\"metrics\"][\"regression\"]\n",
    "        \n",
    "        self.PRIMARY_METRIC = metrics_cfg[\"primary_metric\"]\n",
    "        self.DIRECTION = metrics_cfg[\"direction\"]\n",
    "        self.TRACKED_METRICS = metrics_cfg[\"tracked_metrics\"]\n",
    "        \n",
    "        # UAT configuration\n",
    "        self.UAT_ENABLED = pipeline_cfg[\"uat\"][\"enabled\"]\n",
    "        \n",
    "        if MODEL_TYPE in [\"random_forest\", \"logistic_regression\", \"xgboost_classifier\"]:\n",
    "            self.UAT_THRESHOLDS = pipeline_cfg[\"uat\"][\"classification_thresholds\"]\n",
    "        else:\n",
    "            self.UAT_THRESHOLDS = pipeline_cfg[\"uat\"][\"regression_thresholds\"]\n",
    "        \n",
    "        # Tables\n",
    "        self.UAT_RESULTS_TABLE = pipeline_cfg[\"tables\"][\"uat_results\"]\n",
    "        self.EVALUATION_LOG_TABLE = pipeline_cfg[\"tables\"][\"evaluation_log\"]\n",
    "        \n",
    "        # Slack notifications\n",
    "        self.SLACK_ENABLED = pipeline_cfg[\"notifications\"][\"enabled\"]\n",
    "        self.SLACK_WEBHOOK_URL = self._get_slack_webhook()\n",
    "        \n",
    "        # Duplicate detection tolerance\n",
    "        self.TOLERANCE = 1e-6\n",
    "        \n",
    "        print(f\"\\nüìä Configuration Summary:\")\n",
    "        print(f\"   Model Type: {self.MODEL_TYPE.upper()}\")\n",
    "        print(f\"   Model Name: {self.MODEL_NAME}\")\n",
    "        print(f\"   Staging Alias: @{self.STAGING_ALIAS}\")\n",
    "        print(f\"   Production Alias: @{self.PRODUCTION_ALIAS}\")\n",
    "        print(f\"   Primary Metric: {self.PRIMARY_METRIC} ({self.DIRECTION})\")\n",
    "        print(f\"   UAT Validation: {'ENABLED' if self.UAT_ENABLED else 'DISABLED'}\")\n",
    "        print(f\"   Slack Notifications: {'ENABLED' if self.SLACK_WEBHOOK_URL else 'DISABLED'}\")\n",
    "    \n",
    "    def _get_slack_webhook(self) -> Optional[str]:\n",
    "        \"\"\"Safely retrieve Slack webhook URL from Databricks secrets\"\"\"\n",
    "        if not self.SLACK_ENABLED:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            scopes = [\"shared-scope\", \"dev-scope\", \"prod-scope\", \"ml-scope\"]\n",
    "            for scope in scopes:\n",
    "                try:\n",
    "                    webhook = dbutils.secrets.get(scope, \"SLACK_WEBHOOK_URL\")\n",
    "                    if webhook and webhook.strip():\n",
    "                        print(f\"   ‚úÖ Slack webhook found in scope '{scope}'\")\n",
    "                        return webhook\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            print(\"   ‚ÑπÔ∏è  No Slack webhook found in secrets\")\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Could not access secrets: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize config\n",
    "config = Config()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# üì¢ SLACK NOTIFICATION HELPER\n",
    "\n",
    "class SlackNotifier:\n",
    "    \"\"\"Slack notification handler\"\"\"\n",
    "    \n",
    "    def __init__(self, webhook_url: Optional[str]):\n",
    "        self.webhook_url = webhook_url\n",
    "        self.enabled = webhook_url is not None and webhook_url.strip() != \"\"\n",
    "        \n",
    "    def send(self, message: str, level: str = \"info\", extra_fields: Optional[Dict] = None) -> bool:\n",
    "        \"\"\"Send Slack notification\"\"\"\n",
    "        if not self.enabled:\n",
    "            print(f\"üì¢ [SLACK DISABLED] {message}\")\n",
    "            return False\n",
    "        \n",
    "        emoji_map = {\n",
    "            \"info\": \"‚ÑπÔ∏è\",\n",
    "            \"success\": \"‚úÖ\",\n",
    "            \"warning\": \"‚ö†Ô∏è\",\n",
    "            \"error\": \"‚ùå\",\n",
    "            \"rocket\": \"üöÄ\",\n",
    "            \"trophy\": \"üèÜ\"\n",
    "        }\n",
    "        \n",
    "        formatted_message = f\"{emoji_map.get(level, '‚ÑπÔ∏è')} *{message}*\"\n",
    "        \n",
    "        if extra_fields:\n",
    "            formatted_message += \"\\n\"\n",
    "            for key, value in extra_fields.items():\n",
    "                formatted_message += f\"\\n‚Ä¢ *{key}:* {value}\"\n",
    "        \n",
    "        payload = {\n",
    "            \"text\": formatted_message,\n",
    "            \"username\": \"ML Pipeline Bot\",\n",
    "            \"icon_emoji\": \":rocket:\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.webhook_url,\n",
    "                json=payload,\n",
    "                timeout=5\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print(f\"üì¢ Slack notification sent successfully\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Slack error: {response.status_code}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Slack notification failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def send_promotion_success(self, model_name: str, version: int, metrics: Dict) -> bool:\n",
    "        \"\"\"Send success notification for production promotion\"\"\"\n",
    "        extra = {\n",
    "            \"Model\": model_name,\n",
    "            \"Version\": f\"v{version}\",\n",
    "            \"Status\": \"LIVE in Production üéâ\",\n",
    "            \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        # Add key metrics\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            if metric_value is not None:\n",
    "                if isinstance(metric_value, float):\n",
    "                    extra[metric_name] = f\"{metric_value:.4f}\"\n",
    "                else:\n",
    "                    extra[metric_name] = str(metric_value)\n",
    "        \n",
    "        return self.send(\n",
    "            \"Production Deployment Successful\",\n",
    "            level=\"rocket\",\n",
    "            extra_fields=extra\n",
    "        )\n",
    "    \n",
    "    def send_promotion_blocked(self, model_name: str, reason: str) -> bool:\n",
    "        \"\"\"Send notification when promotion is blocked\"\"\"\n",
    "        extra = {\n",
    "            \"Model\": model_name,\n",
    "            \"Reason\": reason,\n",
    "            \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        return self.send(\n",
    "            \"Production Promotion Blocked\",\n",
    "            level=\"warning\",\n",
    "            extra_fields=extra\n",
    "        )\n",
    "    \n",
    "    def send_error(self, error_message: str, details: Optional[str] = None) -> bool:\n",
    "        \"\"\"Send error notification\"\"\"\n",
    "        extra = {\n",
    "            \"Error\": error_message,\n",
    "            \"Timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        if details:\n",
    "            extra[\"Details\"] = details\n",
    "        \n",
    "        return self.send(\n",
    "            \"Production Promotion Failed\",\n",
    "            level=\"error\",\n",
    "            extra_fields=extra\n",
    "        )\n",
    "\n",
    "# Initialize Slack notifier\n",
    "slack = SlackNotifier(config.SLACK_WEBHOOK_URL)\n",
    " \n",
    "# ‚úÖ INITIALIZE MLFLOW & SPARK\n",
    "\n",
    "print(\"\\nüîß Step 2: Initializing MLflow and Spark...\")\n",
    "\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"ProductionPromotion\").getOrCreate()\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    print(\"‚úÖ MLflow and Spark initialized successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize: {e}\")\n",
    "    slack.send_error(\"Initialization failed\", str(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "# Send startup notification\n",
    "slack.send(\n",
    "    \"Production Promotion Pipeline Started\",\n",
    "    level=\"info\",\n",
    "    extra_fields={\n",
    "        \"Model\": config.MODEL_NAME,\n",
    "        \"Model Type\": config.MODEL_TYPE.upper()\n",
    "    }\n",
    ")\n",
    " \n",
    "## üîßHELPER FUNCTIONS\n",
    "\n",
    "def wait_until_ready(version: int, timeout: int = 300) -> bool:\n",
    "    \"\"\"Wait for model version to become READY\"\"\"\n",
    "    print(f\"\\n‚è≥ Waiting for model v{version} to become READY...\")\n",
    "    \n",
    "    start = time.time()\n",
    "    while time.time() - start < timeout:\n",
    "        try:\n",
    "            mv = client.get_model_version(config.MODEL_NAME, version)\n",
    "            status = mv.status\n",
    "            \n",
    "            if status == \"READY\":\n",
    "                print(f\"   ‚úÖ Model v{version} is READY\")\n",
    "                return True\n",
    "            elif status == \"FAILED_REGISTRATION\":\n",
    "                print(f\"   ‚ùå Model v{version} registration FAILED\")\n",
    "                return False\n",
    "            \n",
    "            print(f\"   ‚è≥ Status: {status} (waiting...)\")\n",
    "            time.sleep(5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error checking status: {e}\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    print(f\"   ‚è∞ Timeout: Model v{version} not ready after {timeout}s\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_metric_from_run(run_id: str) -> Optional[float]:\n",
    "    \"\"\"Get primary metric value from MLflow run\"\"\"\n",
    "    try:\n",
    "        run = client.get_run(run_id)\n",
    "        metric_value = run.data.metrics.get(config.PRIMARY_METRIC)\n",
    "        return metric_value\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not get metric from run {run_id}: {e}\")\n",
    "        return None\n",
    " \n",
    "# üìã STEP 1: GET STAGING MODEL\n",
    " \n",
    "def get_staging_model() -> Optional[Dict]:\n",
    "    \"\"\"Get current staging model version\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 1: Finding Staging Model\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Looking for: {config.MODEL_NAME}@{config.STAGING_ALIAS}\")\n",
    "        \n",
    "        # Get model version by alias\n",
    "        staging_mv = client.get_model_version_by_alias(\n",
    "            config.MODEL_NAME,\n",
    "            config.STAGING_ALIAS\n",
    "        )\n",
    "        \n",
    "        version = int(staging_mv.version)\n",
    "        run_id = staging_mv.run_id\n",
    "        status = staging_mv.status\n",
    "        \n",
    "        print(f\"‚úÖ Staging model found:\")\n",
    "        print(f\"   Version: v{version}\")\n",
    "        print(f\"   Run ID: {run_id}\")\n",
    "        print(f\"   Status: {status}\")\n",
    "        \n",
    "        # Get metric from run\n",
    "        metric_value = get_metric_from_run(run_id)\n",
    "        \n",
    "        if metric_value is not None:\n",
    "            print(f\"   {config.PRIMARY_METRIC}: {metric_value:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'version': version,\n",
    "            'run_id': run_id,\n",
    "            'status': status,\n",
    "            'metric': metric_value\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå No staging model found: {e}\")\n",
    "        print(f\"üí° Please run uat_staging.py first to promote a model to @{config.STAGING_ALIAS}\")\n",
    "        return None\n",
    " \n",
    "# üìã STEP 2: CHECK UAT STATUS\n",
    "\n",
    "def check_uat_status(staging_version: int) -> Tuple[bool, Optional[Dict]]:\n",
    "    \"\"\"Check if staging model passed UAT validation\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 2: Checking UAT Status\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if not config.UAT_ENABLED:\n",
    "        print(\"‚ÑπÔ∏è  UAT validation disabled in config\")\n",
    "        return True, None\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Reading UAT results from: {config.UAT_RESULTS_TABLE}\")\n",
    "        \n",
    "        # Read UAT results table\n",
    "        uat_df = spark.table(config.UAT_RESULTS_TABLE).toPandas()\n",
    "        \n",
    "        if uat_df.empty:\n",
    "            print(f\"‚ö†Ô∏è  No UAT results found in table\")\n",
    "            print(f\"üí° Please run uat_inference.py first\")\n",
    "            return False, None\n",
    "        \n",
    "        print(f\"üìä Found {len(uat_df)} UAT result(s) in total\")\n",
    "        \n",
    "        # Handle both string and int version formats\n",
    "        version_str = str(staging_version)\n",
    "        version_int = int(staging_version)\n",
    "        \n",
    "        # Filter for this version\n",
    "        version_results = uat_df[\n",
    "            (uat_df['model_version'] == version_str) | \n",
    "            (uat_df['model_version'] == version_int)\n",
    "        ]\n",
    "        \n",
    "        if version_results.empty:\n",
    "            print(f\"‚ö†Ô∏è  No UAT results found for version v{staging_version}\")\n",
    "            print(f\"\\nüìã Available UAT results:\")\n",
    "            print(uat_df[['timestamp', 'model_version', 'uat_status']].to_string(index=False))\n",
    "            print(f\"\\nüí° Run uat_inference.py for this version first\")\n",
    "            return False, None\n",
    "        \n",
    "        # Get latest result for this version\n",
    "        latest_result = version_results.sort_values('timestamp', ascending=False).iloc[0]\n",
    "        uat_status = latest_result['uat_status']\n",
    "        \n",
    "        print(f\"\\nüìä UAT Results for v{staging_version}:\")\n",
    "        print(f\"   Timestamp: {latest_result['timestamp']}\")\n",
    "        print(f\"   UAT Status: {uat_status}\")\n",
    "        print(f\"   Model Type: {latest_result.get('model_type', config.MODEL_TYPE)}\")\n",
    "        \n",
    "        # Extract metrics based on model type\n",
    "        metrics = {}\n",
    "        \n",
    "        if config.MODEL_TYPE in [\"random_forest\", \"logistic_regression\", \"xgboost_classifier\"]:\n",
    "            # Classification metrics\n",
    "            metrics = {\n",
    "                'accuracy': float(latest_result.get('accuracy', 0)),\n",
    "                'precision': float(latest_result.get('precision', 0)),\n",
    "                'recall': float(latest_result.get('recall', 0)),\n",
    "                'f1': float(latest_result.get('f1', 0)),\n",
    "                'roc_auc': float(latest_result.get('roc_auc', 0)) if latest_result.get('roc_auc') else None\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n   Classification Metrics:\")\n",
    "            print(f\"     ‚Ä¢ Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "            print(f\"     ‚Ä¢ Precision: {metrics['precision']:.4f}\")\n",
    "            print(f\"     ‚Ä¢ Recall:    {metrics['recall']:.4f}\")\n",
    "            print(f\"     ‚Ä¢ F1 Score:  {metrics['f1']:.4f}\")\n",
    "            if metrics['roc_auc']:\n",
    "                print(f\"     ‚Ä¢ ROC-AUC:   {metrics['roc_auc']:.4f}\")\n",
    "        else:\n",
    "            # Regression metrics\n",
    "            metrics = {\n",
    "                'mae': float(latest_result.get('mae', 0)),\n",
    "                'rmse': float(latest_result.get('rmse', 0)),\n",
    "                'r2': float(latest_result.get('r2', 0)),\n",
    "                'mape': float(latest_result.get('mape', 0))\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n   Regression Metrics:\")\n",
    "            print(f\"     ‚Ä¢ MAE:  {metrics['mae']:.4f}\")\n",
    "            print(f\"     ‚Ä¢ RMSE: {metrics['rmse']:.4f}\")\n",
    "            print(f\"     ‚Ä¢ R¬≤:   {metrics['r2']:.4f}\")\n",
    "            print(f\"     ‚Ä¢ MAPE: {metrics['mape']:.2f}%\")\n",
    "        \n",
    "        if uat_status == \"PASSED\":\n",
    "            print(f\"\\n‚úÖ Model v{staging_version} PASSED UAT validation\")\n",
    "            return True, metrics\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Model v{staging_version} FAILED UAT validation\")\n",
    "            \n",
    "            # Show failed checks if available\n",
    "            if 'failed_checks_json' in latest_result and latest_result['failed_checks_json']:\n",
    "                import json\n",
    "                failed_checks = json.loads(latest_result['failed_checks_json'])\n",
    "                print(f\"\\n   Failed checks ({len(failed_checks)}):\")\n",
    "                for check in failed_checks:\n",
    "                    print(f\"     ‚Ä¢ {check}\")\n",
    "            \n",
    "            return False, metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to check UAT status: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False, None\n",
    "\n",
    "# üìã STEP 3: GET CURRENT PRODUCTION MODEL (OPTIONAL)\n",
    "\n",
    "def get_current_production_model() -> Optional[Dict]:\n",
    "    \"\"\"Get current production model (if exists)\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 3: Checking Current Production Model\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        prod_mv = client.get_model_version_by_alias(\n",
    "            config.MODEL_NAME,\n",
    "            config.PRODUCTION_ALIAS\n",
    "        )\n",
    "        \n",
    "        version = int(prod_mv.version)\n",
    "        run_id = prod_mv.run_id\n",
    "        metric_value = get_metric_from_run(run_id)\n",
    "        \n",
    "        print(f\"‚ÑπÔ∏è  Current production model:\")\n",
    "        print(f\"   Version: v{version}\")\n",
    "        print(f\"   Run ID: {run_id}\")\n",
    "        if metric_value is not None:\n",
    "            print(f\"   {config.PRIMARY_METRIC}: {metric_value:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'version': version,\n",
    "            'run_id': run_id,\n",
    "            'metric': metric_value\n",
    "        }\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"‚ÑπÔ∏è  No production model exists yet (first deployment)\")\n",
    "        return None\n",
    " \n",
    "# üìã STEP 4: COMPARE STAGING VS PRODUCTION (OPTIONAL)\n",
    " \n",
    "\n",
    "def should_promote(staging: Dict, production: Optional[Dict]) -> Tuple[bool, str]:\n",
    "    \"\"\"Determine if staging should replace production\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 4: Performance Comparison\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if production is None:\n",
    "        print(\"‚úÖ First production deployment - proceeding\")\n",
    "        return True, \"First production deployment\"\n",
    "    \n",
    "    staging_metric = staging.get('metric')\n",
    "    prod_metric = production.get('metric')\n",
    "    \n",
    "    if staging_metric is None or prod_metric is None:\n",
    "        print(\"‚ö†Ô∏è  Cannot compare metrics - proceeding anyway\")\n",
    "        return True, \"Metrics unavailable for comparison\"\n",
    "    \n",
    "    print(f\"\\nüìä Metric Comparison ({config.PRIMARY_METRIC}):\")\n",
    "    print(f\"   Staging:    {staging_metric:.4f}\")\n",
    "    print(f\"   Production: {prod_metric:.4f}\")\n",
    "    \n",
    "    # Check if metrics are essentially equal\n",
    "    if abs(staging_metric - prod_metric) <= config.TOLERANCE:\n",
    "        print(f\"\\n‚ö†Ô∏è  Metrics are equal (within tolerance {config.TOLERANCE})\")\n",
    "        return False, \"No improvement - metrics equal\"\n",
    "    \n",
    "    # Compare based on direction\n",
    "    if config.DIRECTION == \"maximize\":\n",
    "        if staging_metric > prod_metric:\n",
    "            improvement = ((staging_metric - prod_metric) / prod_metric) * 100\n",
    "            print(f\"\\n‚úÖ Staging is better (+{improvement:.2f}% improvement)\")\n",
    "            return True, f\"Performance improved by {improvement:.2f}%\"\n",
    "        else:\n",
    "            decline = ((prod_metric - staging_metric) / prod_metric) * 100\n",
    "            print(f\"\\n‚ùå Staging is worse (-{decline:.2f}% decline)\")\n",
    "            return False, f\"Performance declined by {decline:.2f}%\"\n",
    "    else:  # minimize\n",
    "        if staging_metric < prod_metric:\n",
    "            improvement = ((prod_metric - staging_metric) / prod_metric) * 100\n",
    "            print(f\"\\n‚úÖ Staging is better (-{improvement:.2f}% improvement)\")\n",
    "            return True, f\"Performance improved by {improvement:.2f}%\"\n",
    "        else:\n",
    "            decline = ((staging_metric - prod_metric) / prod_metric) * 100\n",
    "            print(f\"\\n‚ùå Staging is worse (+{decline:.2f}% decline)\")\n",
    "            return False, f\"Performance declined by {decline:.2f}%\"\n",
    " \n",
    "# üìã STEP 5: PROMOTE TO PRODUCTION\n",
    " \n",
    "def promote_to_production(staging: Dict, uat_metrics: Optional[Dict]) -> bool:\n",
    "    \"\"\"Promote staging model to production\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 5: Promoting to Production\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    version = staging['version']\n",
    "    \n",
    "    # Wait for model to be ready\n",
    "    print(f\"\\n‚è≥ Ensuring model v{version} is READY...\")\n",
    "    if not wait_until_ready(version):\n",
    "        print(f\"‚ùå Model v{version} is not ready for promotion\")\n",
    "        slack.send_promotion_blocked(\n",
    "            config.MODEL_NAME,\n",
    "            f\"Model v{version} is not in READY state\"\n",
    "        )\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nüöÄ Setting @{config.PRODUCTION_ALIAS} alias to v{version}...\")\n",
    "        \n",
    "        client.set_registered_model_alias(\n",
    "            name=config.MODEL_NAME,\n",
    "            alias=config.PRODUCTION_ALIAS,\n",
    "            version=version\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚úÖ‚úÖ PRODUCTION PROMOTION SUCCESSFUL ‚úÖ‚úÖ\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"\\nüéâ Model Deployed to Production!\")\n",
    "        print(f\"   Model: {config.MODEL_NAME}\")\n",
    "        print(f\"   Model Type: {config.MODEL_TYPE.upper()}\")\n",
    "        print(f\"   Version: v{version}\")\n",
    "        print(f\"   Promoted: @{config.STAGING_ALIAS} ‚Üí @{config.PRODUCTION_ALIAS}\")\n",
    "        print(f\"   Run ID: {staging['run_id']}\")\n",
    "        \n",
    "        if staging.get('metric'):\n",
    "            print(f\"   {config.PRIMARY_METRIC}: {staging['metric']:.4f}\")\n",
    "        \n",
    "        if uat_metrics:\n",
    "            print(f\"\\nüìä UAT Performance Metrics:\")\n",
    "            for metric_name, metric_value in uat_metrics.items():\n",
    "                if metric_value is not None:\n",
    "                    if isinstance(metric_value, float):\n",
    "                        print(f\"   {metric_name}: {metric_value:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric_name}: {metric_value}\")\n",
    "        \n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Send success notification\n",
    "        slack.send_promotion_success(\n",
    "            config.MODEL_NAME,\n",
    "            version,\n",
    "            uat_metrics or {}\n",
    "        )\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Failed to promote model: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        slack.send_error(\n",
    "            \"Production promotion failed\",\n",
    "            str(e)\n",
    "        )\n",
    "        \n",
    "        return False\n",
    " \n",
    "# üé¨ MAIN EXECUTION\n",
    " \n",
    "def main():\n",
    "    \"\"\"Main production promotion pipeline\"\"\"\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üé¨ STARTING PRODUCTION PROMOTION PIPELINE\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Step 1: Get staging model\n",
    "        staging = get_staging_model()\n",
    "        if not staging:\n",
    "            error_msg = f\"No staging model found - please run uat_staging.py first\"\n",
    "            print(f\"\\n‚ùå {error_msg}\")\n",
    "            slack.send_promotion_blocked(config.MODEL_NAME, error_msg)\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # Step 2: Check UAT status\n",
    "        uat_passed, uat_metrics = check_uat_status(staging['version'])\n",
    "        \n",
    "        if not uat_passed:\n",
    "            warning_msg = (\n",
    "                f\"UAT validation not passed for v{staging['version']}\"\n",
    "            )\n",
    "            print(f\"\\n‚ö†Ô∏è  {warning_msg}\")\n",
    "            print(f\"üí° Model cannot be promoted to production\")\n",
    "            print(f\"üí° Please ensure UAT validation passes before promotion\")\n",
    "            \n",
    "            slack.send_promotion_blocked(config.MODEL_NAME, warning_msg)\n",
    "            \n",
    "            print(\"\\nüõë Stopping execution - UAT validation required\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        print(f\"\\n‚úÖ UAT validation passed - proceeding with promotion\")\n",
    "        \n",
    "        # Step 3: Get current production model (optional comparison)\n",
    "        production = get_current_production_model()\n",
    "        \n",
    "        # Step 4: Compare performance (optional)\n",
    "        should_proceed, reason = should_promote(staging, production)\n",
    "        \n",
    "        if not should_proceed:\n",
    "            print(f\"\\n‚ö†Ô∏è  Promotion skipped: {reason}\")\n",
    "            print(f\"üí° Staging model does not improve upon current production\")\n",
    "            \n",
    "            slack.send_promotion_blocked(config.MODEL_NAME, reason)\n",
    "            \n",
    "            # Save task values\n",
    "            try:\n",
    "                dbutils.jobs.taskValues.set(key=\"promotion_status\", value=\"SKIPPED\")\n",
    "                dbutils.jobs.taskValues.set(key=\"reason\", value=reason)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            sys.exit(0)\n",
    "        \n",
    "        # Step 5: Promote to production\n",
    "        success = promote_to_production(staging, uat_metrics)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\n‚ú® Production promotion completed successfully!\")\n",
    "            print(f\"\\nüìå Next Steps:\")\n",
    "            print(f\"   1. Monitor model performance in production\")\n",
    "            print(f\"   2. Set up model serving endpoint (if needed)\")\n",
    "            print(f\"   3. Update API/application to use new version\")\n",
    "            \n",
    "            # Save task values for workflow\n",
    "            try:\n",
    "                dbutils.jobs.taskValues.set(key=\"production_version\", value=staging['version'])\n",
    "                dbutils.jobs.taskValues.set(key=\"model_type\", value=config.MODEL_TYPE)\n",
    "                dbutils.jobs.taskValues.set(key=\"promotion_status\", value=\"SUCCESS\")\n",
    "                print(\"\\n‚úÖ Task values saved for workflow\")\n",
    "            except:\n",
    "                print(\"\\n‚ÑπÔ∏è  Not running in workflow - skipping task values\")\n",
    "            \n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Production promotion failed\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚ùå PRODUCTION PROMOTION FAILED\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        slack.send_error(\n",
    "            \"Production promotion pipeline failed\",\n",
    "            str(e)\n",
    "        )\n",
    "        \n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)\n",
    " \n",
    "# ‚úÖ EXECUTE\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
