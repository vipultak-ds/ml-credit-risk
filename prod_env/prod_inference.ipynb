{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8687be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ PRODUCTION BATCH INFERENCE \n",
    " \n",
    "from databricks.sdk import WorkspaceClient\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import traceback\n",
    "import sys  # ‚Üê ADDED\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ PRODUCTION INFERENCE PIPELINE (NEW WORKFLOW)\")\n",
    "print(\"=\" * 80)\n",
    " \n",
    "# 1Ô∏è‚É£ Load pipeline configuration\n",
    " \n",
    "print(\"\\nüìã Loading pipeline_config.yml...\")\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    config_path = \"/Workspace/Repos/vipultak7171@gmail.com/ml-credit-risk/dev_env/pipeline_config.yml\"\n",
    "    \n",
    "    if not os.path.exists(config_path):\n",
    "        config_path = \"pipeline_config.yml\"  # fallback if repo path fails\n",
    "\n",
    "    with open(config_path, \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "\n",
    "    MODEL_TYPE = pipeline_cfg[\"model\"][\"type\"]\n",
    "    BASE_NAME = pipeline_cfg[\"model\"][\"base_name\"]\n",
    "\n",
    "    # ‚úÖ NEW: Dynamic endpoint name from YAML format rule\n",
    "    ENDPOINT_NAME = pipeline_cfg[\"serving\"][\"endpoint_name_format\"].format(\n",
    "        base_name=BASE_NAME.replace(\"_\", \"-\"),\n",
    "        model_type=MODEL_TYPE\n",
    "    )\n",
    "\n",
    "    data_cfg = pipeline_cfg[\"data\"]\n",
    "    INPUT_TABLE = data_cfg[\"input_table\"]\n",
    "    FEATURES = data_cfg[\"features\"]\n",
    "    LABEL = data_cfg[\"label\"]\n",
    "\n",
    "    # ‚úÖ NEW: Dynamic output table based on YAML format rule\n",
    "    inference_cfg = pipeline_cfg.get(\"inference\", {})\n",
    "    OUTPUT_TABLE = inference_cfg[\"output_table_format\"].format(\n",
    "        catalog=pipeline_cfg[\"model\"][\"catalog\"],\n",
    "        schema=pipeline_cfg[\"model\"][\"schema\"],\n",
    "        model_type=MODEL_TYPE\n",
    "    )\n",
    "\n",
    "    BATCH_SIZE = inference_cfg.get(\"batch_size\", 100)\n",
    "\n",
    "    print(f\"üìå Using configs:\")\n",
    "    print(f\"   ‚û§ Endpoint: {ENDPOINT_NAME}\")\n",
    "    print(f\"   ‚û§ Input Table: {INPUT_TABLE}\")\n",
    "    print(f\"   ‚û§ Output Table: {OUTPUT_TABLE}\")\n",
    "    print(f\"   ‚û§ Batch Size: {BATCH_SIZE}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load config: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    " \n",
    "# 2Ô∏è‚É£ Initialize clients\n",
    "\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"ProductionInference\").getOrCreate()\n",
    "    ws = WorkspaceClient()\n",
    "    print(\"\\n‚úÖ Spark + WorkspaceClient initialized\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Initialization failed: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    " \n",
    "# 3Ô∏è‚É£ Load input data\n",
    " \n",
    "print(f\"\\nüì• Loading data from {INPUT_TABLE}...\")\n",
    "\n",
    "try:\n",
    "    df = spark.read.table(INPUT_TABLE).toPandas()\n",
    "\n",
    "    # Validate required features\n",
    "    missing = [col for col in FEATURES if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing input features: {missing}\")\n",
    "\n",
    "    if LABEL not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è No label column found ‚Üí metrics will be skipped\")\n",
    "\n",
    "    print(f\"üìå Total records: {len(df):,}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data load error: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    " \n",
    "# 4Ô∏è‚É£ Run inference using Serving Endpoint\n",
    "\n",
    "print(\"\\nüîÑ Running inference through serving endpoint...\")\n",
    "\n",
    "predictions = []\n",
    "n_batches = (len(df) // BATCH_SIZE) + 1\n",
    "\n",
    "try:\n",
    "    for i in range(n_batches):\n",
    "        batch = df.iloc[i * BATCH_SIZE : (i+1) * BATCH_SIZE]\n",
    "\n",
    "        if batch.empty:\n",
    "            continue\n",
    "\n",
    "        response = ws.serving_endpoints.query(\n",
    "            name=ENDPOINT_NAME,\n",
    "            dataframe_records=batch[FEATURES].to_dict(\"records\")\n",
    "        )\n",
    "\n",
    "        predictions.extend(response.predictions)\n",
    "        \n",
    "        if (i + 1) % 10 == 0 or (i + 1) == n_batches:\n",
    "            print(f\"   Processed batch {i+1}/{n_batches}\")\n",
    "\n",
    "    print(f\"‚úÖ Inference complete: {len(predictions)} predictions generated\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Inference failed: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    " \n",
    "# 5Ô∏è‚É£ Build output dataframe\n",
    " \n",
    "print(\"\\nüì¶ Preparing output results...\")\n",
    "\n",
    "df[\"prediction\"] = predictions\n",
    "\n",
    "# üîß Ensure prediction is integer before converting\n",
    "df[\"prediction\"] = pd.to_numeric(df[\"prediction\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# üî• Convert prediction to human readable Yes/No\n",
    "label_mapping = {0: \"No\", 1: \"Yes\"}\n",
    "df[\"prediction_label\"] = df[\"prediction\"].map(label_mapping)\n",
    "\n",
    "\n",
    "df[\"prediction_timestamp\"] = datetime.now()\n",
    "df[\"model_type\"] = MODEL_TYPE.upper()\n",
    "df[\"endpoint\"] = ENDPOINT_NAME\n",
    " \n",
    "# 6Ô∏è‚É£ Save to Delta Table\n",
    " \n",
    "print(f\"\\nüíæ Saving results to {OUTPUT_TABLE}...\")\n",
    "\n",
    "try:\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "\n",
    "    spark_df.write.mode(\"append\").format(\"delta\").option(\"mergeSchema\", \"true\").saveAsTable(OUTPUT_TABLE)\n",
    "\n",
    "    print(f\"‚úÖ Results saved to: {OUTPUT_TABLE}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Write failure but continuing: {e}\")\n",
    "    traceback.print_exc()\n",
    " \n",
    "# 7Ô∏è‚É£ Compute model performance (if true labels present)\n",
    "\n",
    "if LABEL in df.columns:\n",
    "    print(\"\\nüìä Evaluating model performance (Classification)...\")\n",
    "\n",
    "    # üîß FIX seed true labels to match 0/1 type\n",
    "    y_true = df[LABEL].replace({\"no\": 0, \"yes\": 1}).astype(int)\n",
    "    y_pred = df[\"prediction\"].astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        metrics[\"roc_auc\"] = roc_auc_score(y_true, y_pred)\n",
    "    except:\n",
    "        metrics[\"roc_auc\"] = None\n",
    "\n",
    "    print(\"üìä Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        if v is not None:\n",
    "            print(f\"   ‚û§ {k}: {round(v,4)}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è No true labels found ‚Üí skipping metrics.\")\n",
    " \n",
    "# 8Ô∏è‚É£ Final Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"üéØ PRODUCTION INFERENCE COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üìå Input Data     : {INPUT_TABLE}\")\n",
    "print(f\"üìå Saved Results  : {OUTPUT_TABLE}\")\n",
    "print(f\"üìå Predictions    : {len(df):,}\")\n",
    "print(f\"üìå Endpoint       : {ENDPOINT_NAME}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"‚úÖ Script completed successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
